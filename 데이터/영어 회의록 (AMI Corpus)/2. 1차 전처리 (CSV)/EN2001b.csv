[00:22] Speaker_C | Yeah .
[00:32] Speaker_B | Hmm ?
"[00:47] Speaker_B | Ah , sod that . Okay , there ."
[00:54] Speaker_B | Group K_ . Da .
[00:58] Speaker_B | Yeah .
"[01:05] Speaker_B | Yeah , I guess . Whatever ."
"[01:10] Speaker_B | It's yeah , I never get this , so what's the point of if this is strapless if this strap's supposed to go behind m I obviously doing this wrong . Obviously failing this like whatev calling centre and tra"
"[01:21] Speaker_C | You you have this going behind your ears , the yeah . Yeah ."
"[01:24] Speaker_B | Like this and then yeah , you know what the shit has to do now ."
[01:35] Speaker_D | Yeah .
[01:37] Speaker_B | Okay .
"[01:46] Speaker_B | Yes , so um actually I just realise I don't have power , let me just switch on the other which is gonna run out ."
[01:57] Speaker_B | Okay .
[01:58] Speaker_D | Okay .
"[02:03] Speaker_B | So there's probably not much to talk about at the moment in terms of like talking about each other's stuff , I mean beyond what we've been talking about yesterday ."
"[02:14] Speaker_D | Yeah , that's true I think ."
"[02:16] Speaker_B | So what I've been thinking is maybe if we try to really make sense together of the X_M_L_ format to be sure that we can all produce the data that we are producing in a way or at least I mean I guess my data I'll probably load in from completely different way anyway because it's matrix , but all this stuff that goes with annotation , that we have it in the right format . Maybe if we just sort of pool what we know about the X_M_L_ format and try to make sense of it . I don't at all know how to go about this ."
[03:00] Speaker_B | Um I downloaded some
[03:07] Speaker_D | Oh yeah .
[03:28] Speaker_D | Yeah .
[03:28] Speaker_C | Hmm .
"[03:36] Speaker_D | Yeah , we haven't got that much to talk about , I don't think ."
[03:37] Speaker_C | No . Just maybe talk about um how you would give me your data file . Yeah .
[03:42] Speaker_D | Yeah .
"[03:44] Speaker_D | Yes , we can do that ."
[03:46] Speaker_B | What's that part ?
[03:48] Speaker_C | That's um the interface between having the topic segments and calculating the uh information importance of words .
[03:53] Speaker_B | Mm-hmm .
[03:57] Speaker_B | Mm-hmm .
[03:58] Speaker_C | Yeah . So I I would need separate files for each segment or just maybe have delimiters inbetween each segment .
[04:03] Speaker_D | Alright .
"[04:08] Speaker_C | Okay , yeah , and y then I can make files of that ."
[04:11] Speaker_C | Alright .
"[04:15] Speaker_C | No , I don't kno know it , no ."
"[04:19] Speaker_C | Yeah , that's fine ."
"[04:21] Speaker_C | I just I just need a a title for the file , but doesn't matter what it is ."
"[04:26] Speaker_D | Right . Okay . Yeah , that's no problem ."
"[04:32] Speaker_B | Yes , so does anyone have a good idea where to start like which what so what is it we talk about getting in at the moment ? We're basically just 'cause the two of you will merge your data together , right ? In some way like i in the end it'll result in one annotation . So the only thing we're trying to tie in is just an additional annotation which is similar to"
[04:42] Speaker_A | Mm yes .
[05:04] Speaker_B | Okay .
"[05:09] Speaker_B | I'm not sure it Ah . See , that's what I was thinking . Not sure what software I have at the moment , which would be hello ?"
[05:11] Speaker_C | Mm .
[05:12] Speaker_A | Mm .
[05:26] Speaker_B | Yeah .
[05:28] Speaker_B | Ah .
"[05:32] Speaker_B | Does anyone know any good standards software displays X_M_L_ , I'm not sure ."
[05:36] Speaker_A | Take Mozilla .
"[05:38] Speaker_B | Yeah , but I'm afraid I only have Firefox and Firefox doesn't have the nice X_M_L_ viewer anymore ."
[05:44] Speaker_D | Hmm .
[05:44] Speaker_B | I think I don't have Mozilla .
[05:50] Speaker_B | No .
[05:54] Speaker_B | I can probably just Emacs them .
"[05:58] Speaker_C | So uh we have then when we are mixing our um values together , is it um a value for each um expression , for each sentence or something ?"
"[06:10] Speaker_A | Yeah , I think that would be m I mean uh for me it's quite difficult to say o on ,"
[06:12] Speaker_C | Yeah .
"[06:17] Speaker_A | you know , w um what scope one annotation would have ."
[06:21] Speaker_C | Mm-mm .
[06:24] Speaker_A | I think it would be certainly more than one word and
[06:29] Speaker_A | I think it would work best with utterances or segments .
[06:32] Speaker_C | Yeah .
"[06:35] Speaker_C | Yeah , I would just end up with uh values for each word , so I wouldn't have um"
[06:35] Speaker_A | Yep .
[06:42] Speaker_C | any boundaries for segments at all .
"[06:47] Speaker_C | I just I just would have the words , and then how we um how long each expression would be , I don't know ."
"[06:55] Speaker_B | But going from from a word business , wouldn't it be easier to then go back and calculate for each utterance ?"
"[07:00] Speaker_C | Yeah , but what is an utterance . Uh , yeah ."
[07:04] Speaker_A | I think just the segments as they're segmented in the for example in the point se point six five .
[07:05] Speaker_C | Okay .
[07:07] Speaker_B | Yeah .
[07:18] Speaker_A | I think so .
[07:19] Speaker_C | Okay .
"[07:24] Speaker_A | And you would s probably still need um your values for the words , um perhaps for for um the keywords that are displayed"
[07:33] Speaker_C | Mm-hmm .
[07:35] Speaker_A | when you click on something .
[07:39] Speaker_D | Mm .
"[07:40] Speaker_A | Yeah , but that's another representation then , I think , f for the importance measure ."
[07:44] Speaker_B | So d
[07:45] Speaker_C | Yeah .
"[07:47] Speaker_B | Does anyone does anyone know in which file the actual , like what's it called , the splitting into the utterances ?"
[07:48] Speaker_A | Should yeah .
[07:54] Speaker_A | Um po
[07:54] Speaker_D | Um is it not segments ? Or is it dialogue act dialogue acts ?
[07:56] Speaker_A | Yes .
"[07:58] Speaker_A | No , it's not . It's um for example , there's uh B_D_B_O_O_ one C_ point six ."
[08:05] Speaker_B | What does it end with ? Does it with with SAX ?
[08:09] Speaker_B | Does that look like it ?
"[08:12] Speaker_A | Uh I can't see anything very much , but yeah , that's that's it ."
[08:14] Speaker_C | Mm uh-huh .
[08:15] Speaker_B | Okay .
"[08:16] Speaker_D | I think that's it , yeah ."
[08:18] Speaker_B | Be nice .
"[08:18] Speaker_D | Yeah , they've all got an I_D_ for each utterance ."
[08:20] Speaker_B | Let's actually just see if maybe K_ right .
[08:25] Speaker_B | Oh this is how much time you spend just getting the right software going .
"[08:34] Speaker_B | Is that better to see ? I guess yeah , white and black is better to see ."
"[08:39] Speaker_C | Yeah , it's better ."
[08:40] Speaker_A | Can you use a bigger font ?
[08:57] Speaker_B | Okay .
"[09:01] Speaker_A | Okay , so here there's for um each segment um uh that's really all segments , I mean it's it can be words or topics or um anything I think ."
"[09:25] Speaker_D | Yeah , and it's got a different uh file for each speaker ."
[09:29] Speaker_B | But what is this ? I mean this doesn't contain any content . Like any text .
"[09:33] Speaker_D | N no , it just points to the to the words ."
"[09:33] Speaker_A | No , but it yeah ."
"[09:43] Speaker_A | Yeah , it p Oh , well some of them point to the words , other others point to the um dialogue acts . So that's kind of the global thing that ties together other things ."
"[09:48] Speaker_D | Yeah , yeah ."
[09:55] Speaker_B | So what do all these things in this file have in common ? What what are they ?
[10:14] Speaker_B | Okay . And
"[10:24] Speaker_A | Yeah , it looks uh uh the segment thing looks in the into the words X_M_L_ file and the dialogue acts"
[10:34] Speaker_B | A dialogue act uh a dialogue act annotations of dialogue act . So is that just another representation of text ?
"[10:41] Speaker_A | No , their their annotation of dialogue acts , and one um segment can have or one um of those word strings that are presented in one line can have several um dialogue acts annotated on it ."
"[10:58] Speaker_B | Just see , can we have this files somewhere . So the stuff that's"
[11:03] Speaker_B | that's called segment here that do we know which file this is pulling from ?
"[11:07] Speaker_B | From yeah , it's it's c it from words X_M_L_ , is that it's saying here ?"
"[11:08] Speaker_A | Yeah , it's from words ."
[11:11] Speaker_A | Yes .
[11:17] Speaker_A | That's just below .
[11:20] Speaker_C | So we n would need a value label for each of those segments that are not dialogue acts .
[11:30] Speaker_C | For all those that point to the actual words .
"[11:34] Speaker_B | Okay , let me just try to get them all to a different screen ."
"[11:51] Speaker_B | Sorry , I'm just I'm trying to arrange them , so that we have one above the other , so to make some sense of that ."
"[12:10] Speaker_A | But I think these segments are perhaps not exactly what we are looking at , because that's just o one tying all the others together ."
[12:19] Speaker_A | And the information or r I mean we are going to create a file that looks more like um the words file .
[12:26] Speaker_A | I think .
[12:38] Speaker_B | To a certain position in the in the words file .
"[12:43] Speaker_D | Yeah , think so ."
"[12:48] Speaker_B | So it's that non-vocal sound one here . That's the mic noise , okay ."
"[12:54] Speaker_B | But what's the does it always just oh no , it's it's referencing to several word structures . So this would be basically be a a sequence , right ?"
[13:03] Speaker_A | Yes .
[13:04] Speaker_B | So that's from W_ fifty two .
"[13:10] Speaker_B | Are they not ordered or oh yeah , from W_ fifty two down to W_ what are we talking about ? And yeah , w sorry ."
"[13:11] Speaker_A | Yeah , they are ."
"[13:18] Speaker_A | Um to discourse marker , DIS F_ marker fi point five ."
"[13:25] Speaker_A | Yeah , that's there no no , up up . Go up . Yeah , right ."
"[13:25] Speaker_C | Yeah , that's there . No , above ."
[13:29] Speaker_C | Yeah .
[13:31] Speaker_B | Okay . So this so this is somebody saying it it doesn't .
"[13:37] Speaker_B | Do we have any confirmation do we actually see from this file who's doing it , just out of interest ?"
[13:37] Speaker_C | Yeah .
"[13:42] Speaker_A | Yeah , this is all the speaker D_ ."
[13:46] Speaker_A | You and the speaker D_ .
"[13:46] Speaker_B | Oh . Sorry , in speaker D_'s file . So this is where he'd like time stops . And then it only starts at a later time , because oh , you don't see when I'm pointing at screen , it's just for this . So then it starts here this time against speaker D_ because in-between there's somebody else ."
"[14:02] Speaker_A | Yes . Um you can see whether there's somebody else or not . You can see that in the w um W_ point um first it's W_ point um five uh fifty four and then it's seventy six , so there are um this number of utterances of other speakers in-between ."
[14:02] Speaker_B | Okay .
[14:15] Speaker_B | Yeah . Okay .
[14:32] Speaker_B | How would that be to best tie in with the system ?
"[14:36] Speaker_A | Yeah , I think we would also need two of those ."
[14:40] Speaker_B | Sorry ?
"[14:41] Speaker_A | Yeah , I think we would have to have the same structure , one that points to it , where we tie together , all our information . So we would perhaps have to make one that's similar ."
[14:50] Speaker_B | Something like something like this or like where you give sort of a reference to a beginning and an end position .
"[14:57] Speaker_A | Yes , and uh then another one that would perhaps give the actual probability value ."
"[15:07] Speaker_A | Yeah , it could could probably be in the same file , I don't know ."
"[15:13] Speaker_A | But if you have several layers , then"
[15:17] Speaker_A | you can't represent them on the same file .
[15:21] Speaker_B | We have for now if we just do something which for every
"[15:25] Speaker_B | segment in here attaches actually can we not tie it to the segments file ? Would that not be the way how they would want it to have to do as if we in the end , if we want to attach to each of those segments one number for now ."
"[15:44] Speaker_A | Yeah , in segment point one . Um there line below ."
"[15:49] Speaker_B | Yeah , so wouldn't it I mean the problem is they've me haven't looked at the exact inner workings of their of their engineered . But you'd think that the easiest way and the way that how it's intended to be would be just ,"
"[16:02] Speaker_B | if we have here a link to the segment , a like an I_D_ for that segment , that we just create another file which links to the segment and then has an additional value which is the number ."
[16:15] Speaker_C | So you mean an a an attribute . Yeah .
"[16:17] Speaker_B | Yeah , yeah ."
"[16:20] Speaker_B | Yeah , oh sorry , I I thought we were talking about having two files ."
"[16:25] Speaker_B | I was think yeah , I I think that I I understood wrong . I thought you were wanting to have two different X_M_L_ files , with one the reference and one just th just the number . And I was thinking that's probably what you meant , just um having like for each sort of of our segments having just the I_D_ , which is referencing to these segments here and another attribute which is the the value ."
[16:47] Speaker_A | Mm-hmm .
"[16:48] Speaker_B | So this whole information we would then store in this Ah , no , that I don't have access to because I didn't download like there's this one meta information file where it describes the structure of all the files and describes which um which attributes they bring in . So we would add that to that file ?"
[17:06] Speaker_D | Mm .
"[17:06] Speaker_B | Saying that sort of we bring in information density . And then we would create the file of that type , which we probably couldn't call it segment . I'm not sure . We probably might have to have a different word for it . I'm not sure if it there's any trouble with it repeating ."
[17:22] Speaker_C | Wouldn't it be easiest to just incorporate a new attribute in in this file ?
[17:28] Speaker_B | In the existing segments file .
"[17:29] Speaker_C | Yeah , I don't know , that's probably not very uh nice but would quite easy , wouldn't it ?"
"[17:38] Speaker_A | But I I mean there's not all the information that is in in the c corpus in there in the segments file . I think that is just the um things that are loaded every time , but we have lazy loading , so it can load more than that . Perhaps we could just try to cope . Um , you know , to"
[17:38] Speaker_C | Yeah .
[18:00] Speaker_A | make our file one of those lazy loaded . But I mean I've no real idea how that works .
[18:06] Speaker_B | What uh what are you saying about the w I th doesn't the lazy loading apply to everything ? I mean that it sort of dynamically loads .
"[18:12] Speaker_A | Yeah , but yes , but it has um , you know , a basic thing that it loads , I think . So for example every time it loads the segment things , it can't it can't not display words , I think ."
[18:28] Speaker_B | You think it i it l it loads the whole of the segments file every time .
[18:28] Speaker_A | And it eras
[18:32] Speaker_A | I think so .
[18:34] Speaker_B | Okay .
[18:34] Speaker_A | That's how I understood it .
[18:37] Speaker_A | Because otherwise in the in the other things there is no information about what the participant name is and so on . So
[18:46] Speaker_A | in the segments file it's really the very basic that have to be displayed for any thing .
[18:53] Speaker_B | Hmm .
[18:54] Speaker_C | But they display the segments in or that the utterances i in their um
"[19:02] Speaker_C | user interface as well , where the words are y um displayed ."
"[19:21] Speaker_B | No but I think it's too early to really like discuss that in detail , because we don't at all understand at the moment how the internal data structure like how the loading works . So maybe if we g if we go ahead , do you think it would be possible for you to do an like something like segments or maybe just a copy of segment which has an attribute for for each segment , um but it is like with a with a value with a density value ."
"[19:47] Speaker_A | Yeah , I thin I mean it wouldn't be difficult to um create a file of the p sh of that shape . I mean that would be no problem ."
"[19:55] Speaker_B | Would it be easier though , because all your methods are sort of not working with their whole time frame structure there . So would it be easy for you to to tie the things together . Like if you're doing it on on the word basis here with those words , that in the end you then tie it back in into the right segment here . I mean"
"[20:11] Speaker_A | Um yeah , I I don't know how about you with your words , but um for my segments were the um F_ zero measurements and all those values I get from there . Um I always store the beg uh start and end time of everything I calculated there , so I would just have to pu put it uh yes ."
[20:20] Speaker_B | Hmm .
"[20:30] Speaker_B | You're doing it time-based at the moment . So this isn't directly having time references , but you can get the oh , it is actually here ."
"[20:37] Speaker_A | Yeah , it is ."
"[20:40] Speaker_B | Okay . So if you slice it up by time , you'd probably be able to just like attach like just some attribute of"
[20:51] Speaker_B | info val just f to each of those segments .
"[20:57] Speaker_A | Uh actu but actually my segments are not always the same as their segments , because and their segments , there are um Pause um pauses sometimes . A"
[21:07] Speaker_B | Mm-hmm .
"[21:08] Speaker_D | Yeah , can you not just leaves those lines blank ?"
"[21:11] Speaker_A | Um yes , but uh yeah , I mean one segment of theirs is sometimes two segments of mine , that's just what I meant ."
[21:16] Speaker_D | Oh alright . Okay .
"[21:21] Speaker_B | 'Kay . Um I don't understand enough of what their data structure is . This probably would be a lot easier would I really understand how they are handling the data internally , 'cause then we c then I could say oh , it's easy to just tie it in if you just have it time-stamped that just reference by words and stuff ."
[21:47] Speaker_B | So you would you're doing i you're doing a word by word base .
"[21:50] Speaker_C | Yeah , the problem is probably that um I extract all the words and then uh I don't um use an I_D_ or something for it , so it would be difficult to write it back to the right position ."
[21:54] Speaker_B | Mm-hmm .
[22:00] Speaker_B | Okay .
"[22:10] Speaker_C | It depends on the position , I think . Yeah ."
[22:12] Speaker_B | It be d depends on the position .
[22:16] Speaker_B | Hmm .
"[22:27] Speaker_B | So what if you if you if you get the results from that software and you go back over it then with that file sort of , you write an algorithm which which then goes back because they they're in the right order still and stuff , right ? So that shouldn't be a problem . Oh but this is by speaker here which makes it slightly more difficult ."
[22:37] Speaker_C | Mm yeah .
[22:42] Speaker_D | Hmm .
[22:45] Speaker_B | The problem is that actually NITE X_M_L_ probably provides a lot of the tools that we'd need to do that .
"[22:50] Speaker_A | Yeah , but for example I made a file that contains just the um start times . It could contain end times and words for all speakers of all meetings . I mean that's just the same thing as I gave , yeah , as I gave to you . But um uh displaying also a start and end times of every word . So you could perhaps use it to match um it with your additional information you got , couldn't you ?"
[22:51] Speaker_C | Mm-hmm .
[23:00] Speaker_B | In in a temporal sequence .
"[23:15] Speaker_D | Yeah , what did you use to make that file ? Just in Perl ? You didn't use an X_M_L_ parser ?"
"[23:17] Speaker_A | Perl , a Perl script , yeah ."
"[23:21] Speaker_A | No , no ."
[23:22] Speaker_D | Okay .
[23:23] Speaker_C | Um would you think it would make sense to just take um file files by speaker . It's it doesn't matter what input I give to um to Rainbow . So I just could g use the files as they are . I don't know if that's that would give an output .
"[23:40] Speaker_B | But but would the information density algorithm still make any sense if you split them up , because I mean the whole I thought the whole thing is that you look at the frequency of a word in that specific how often a word inc occurs in a certain topic versus how often it occurs over the whole corpus and that from that it calculates ."
[23:40] Speaker_D | Hmm .
[23:44] Speaker_C | I don't know .
[23:45] Speaker_A | Mm yeah .
"[23:56] Speaker_C | No , it um I think it's not uh versus the whole corpus . It's um you have certain categories , and you measure which words um have the highest information for one category . So it's the categories across each other I think ."
[24:05] Speaker_B | Mm-hmm .
"[24:22] Speaker_C | Um probably yeah . But yeah , it's it's s strange ."
"[24:26] Speaker_B | Yeah , I have a gut feeling it's not a good idea to split it ."
[24:27] Speaker_A | Because it would then say how it find that it's that speaker .
"[24:30] Speaker_B | Yeah . No , but I mean it can't be that difficult . If you if you already have you have in the right order all the words with a with a score to them , and you have a file which has each word and a time stamp . So those two tied together have each word and its time and"
[24:31] Speaker_D | Hmm .
[24:36] Speaker_C | Yeah .
[24:41] Speaker_A | Yeah .
"[24:46] Speaker_A | It's probability , yeah . Or or value , yeah ."
[24:46] Speaker_B | and and and its proba and its value . Yeah .
"[24:50] Speaker_C | Yeah , but what what the problem is , I don't know exactly . I think the information gain in Rainbow is ordered by the value of the information gain , not I am not sure if I can get the right order and the values ."
[25:07] Speaker_C | That's the problem .
[25:07] Speaker_B | So they're they're at the moment so
"[25:09] Speaker_C | But I um if the order stays the same , it's no problem at all to i just write back again . But if uh it's ordered by information gain , I don't know where the words come from , because it's it has a bag of words representation ."
[25:20] Speaker_D | Hmm .
[25:24] Speaker_B | It appears to me that Rainbow was made for something quite different .
[25:25] Speaker_C | Uh yes . Is it is . It was made for text classification .
[25:28] Speaker_B | Hmm .
"[25:30] Speaker_A | So , could you put the more information back in then ?"
"[25:34] Speaker_B | I actually like um um i are you actually sure that Rainbow is doing a measure , like is returning a measure of what we are trying to measure , 'cause it it seems to me that it's just it sounds like something quite different in in d many aspects ."
"[25:47] Speaker_C | Yeah , um what it actually does is that you you put in some documents , and you have several documents per category ."
[25:53] Speaker_B | Mm-hmm .
"[25:57] Speaker_C | Um and you have several categories . And then it measures um which words are typical for a certain t category . And if you get a new document , it will um compare which words are in that new document . And if there are a lot of words that um are typical for one category , it will assign it to that category , and if it's typical for another one , it will assign it to that one ."
[25:59] Speaker_B | And w
[26:07] Speaker_B | Yeah .
[26:15] Speaker_B | Yeah .
[26:28] Speaker_B | But where do you have the original category information from ?
"[26:31] Speaker_C | Yeah , it's because you have um y um you have um oth different files . If if this is your directory , you have um um a diagra um , a directory one , two and three . And this represents the category . Everything that's in there is in category one . A"
[26:39] Speaker_B | Yeah .
[26:46] Speaker_B | Yeah .
[26:50] Speaker_B | So where do you where do you have them from at the moment the split up ?
"[26:53] Speaker_A | Yeah , but the topic isn't it ? That's a topic information ."
"[26:53] Speaker_C | Yeah , just split it up somehow , yeah ."
"[26:56] Speaker_B | In i in the t in the topics , in the in the human topic s um so you've split them up by topic at the moment ."
[26:57] Speaker_C | Yeah .
"[27:02] Speaker_C | No , I've just um split them up uh somehow um by um there are several documents for"
"[27:14] Speaker_C | um each meeting , and I just put one in each category . So uh it's it's not very sensible at the moment , because I'm waiting for the um topic segments or I'm just yeah ."
"[27:47] Speaker_C | Yeah , yeah , probably . Yeah , maybe it's it's better if I write it myself , because otherwise it's too easy to just split things up into bins , and it it wouldn't be any work at all in terms of programming or something ."
"[28:01] Speaker_B | Yeah , but I'm also just like I think that probably the entropy value at the moment for a word is closer to what we're at the moment looking for . I can just like k k I can sit together with you for twenty minutes and just show you the entropy code that I wrote for my other project and it probably and we should work together because it's we used t we have to we'd use the same matrix as I'm using in my latent semantic analysis , you'd use to calculate entropy scores . And then we'd have um a score which actually which would be the same for the word in each position . So in that sense it's doing something a bit different , and like w basically the score that I'm talking about is a conditional entropy score which just checks how much information , the fact that there's one word tells you about what would be the next word . But that's a relatively good measure of whether that's a very specific word , in which case they are usually words which tell you quite a lot or a very general word which usually doesn't tell you quite a lot ."
[28:15] Speaker_C | Alright .
[28:23] Speaker_C | Mm-hmm .
[28:34] Speaker_C | Mm-hmm .
[28:46] Speaker_A | Mm-hmm .
[28:51] Speaker_A | Yeah .
[28:54] Speaker_C | How does it calculate that actually ?
[29:00] Speaker_C | Okay .
"[29:02] Speaker_A | So how sure or unsure you are about the what's following our b our context measures , yeah ."
"[29:07] Speaker_B | Yes , yes , it has . I mean , I think the official le sort of the official description of what it tells you is um how much that like the fact that a given word occurs tells you about what's the next word's gonna be . Which doesn't sound too exciting , but it it just works out in the way that words which are promiscuous and which occur with everything all over the place have very low a scores on that , and also usually end up being the words which are p"
[29:18] Speaker_A | Yeah .
"[29:32] Speaker_B | Least like expressive , and l contain less information ."
[29:36] Speaker_D | Well like function words and stuff .
"[29:37] Speaker_B | Yeah , function words or just very general nouns . Pr probably like what whatev for example the word computer in that context . You could imagine it to f like be in all in all the contexts ."
[29:43] Speaker_D | Mm .
"[29:46] Speaker_A | But do we have enough informa enough data for that it gives us sensible things ? Because I mean the the words we're look really looking for appear not too often , and if they appear five times in the meeting and they have each time a different , you know , differ some different surrounded words , perhaps we have not enough data ."
"[30:06] Speaker_B | Yeah , so we would we w wouldn't do it by word , we would sorry , okay , um I was I was getting that w actually , sorry , I was getting that wrong , I was getting it from what I did my project . Now in this case , we would do it by per mee words per meeting ."
"[30:23] Speaker_C | Yeah , but that's the sa uh almost I think similar to what I'm doing , because words that are in every class , that are not very informative , but words that are only in one class are are very informative for that class ."
[30:31] Speaker_B | Hmm .
"[30:37] Speaker_B | Yes , it it's probably doing it's probably doing quite the same thing in the end , but I'm just saying like with that thing you would easily have an algorithm which at the moment provides you for each word with a score which we can use ."
[30:46] Speaker_C | Oh okay .
[30:48] Speaker_C | Alright .
"[30:50] Speaker_B | Um no um , I was I was I was describing the wrong thing . In this case we wouldn't be doing how much it tells you about another word . In this case we would be doing given that you know a word , how good is it at predicting from which um specific topic that was ."
"[31:02] Speaker_A | Yeah , okay ."
"[31:04] Speaker_B | So that would yeah , in that sense it's the same thing here ."
"[31:05] Speaker_C | Yeah , that's th yeah ."
[31:07] Speaker_A | Mm-hmm .
[31:21] Speaker_C | For a specific word per
[31:21] Speaker_B | Yeah .
[31:24] Speaker_B | The same word the word yesterday would be would have the same score all over the place .
[31:30] Speaker_C | All over the place . And in my case it would have I think it would have different uh values for each category . But in that category it would have the same value at each place .
[31:38] Speaker_B | Okay .
[31:44] Speaker_B | I c
"[31:54] Speaker_B | But but your category thing depends on that we not just have topic segments , but also that these topic segments we have them in categories ."
[31:54] Speaker_C | Yeah .
[32:03] Speaker_B | You you do wouldn't you need several documents for each category ? Or several segments for each category .
"[32:07] Speaker_C | Um that would be best , but I I would have to look if that ."
[32:12] Speaker_B | Do but will it word without that at all ?
"[32:15] Speaker_C | Um at least it works if there are several categories with each with one document each , but it um yeah ."
"[32:24] Speaker_B | Yeah , I mean s so in our case basically every"
[32:28] Speaker_B | every s topic would be its own category .
"[32:32] Speaker_B | And the question is does the algorithm still make any sense in that I don't understand the algorithm enough for that . But what I'm really like because the entropical um calculation is so simple , maybe we should look into making that score just as a preliminary score that we have . Like it it's a very it gives you like I've looked at the result , it gives you basically something in the end which vaguely tells you just whether a word is a very specific word"
"[32:32] Speaker_C | Yeah , that's the questio yeah , I don't know ."
[32:42] Speaker_C | Mm-hmm .
[32:48] Speaker_C | Mm okay .
[32:57] Speaker_B | or a very general word .
[32:58] Speaker_A | Yes .
"[33:01] Speaker_B | I like there is some hope that probably having just sentences where there's lots of very specific words , if you mark them as being more interesting than the words which are only very general words , that they would get us somewhere ."
"[33:13] Speaker_A | Um and what well , what score would a word get that just occurs once in all the corpus for example ?"
[33:21] Speaker_B | Probably one point zero is very high information value .
[33:25] Speaker_A | Even though there are all the other same topics where it doesn't occur ?
"[33:34] Speaker_B | Yeah , in in a sense I mean this is a bit like the what like document frequency over total frequency ."
[33:40] Speaker_A | Mm-hmm .
[33:42] Speaker_D | Hmm .
[33:45] Speaker_A | So would it be higher-scored than a word that um occurs
[33:52] Speaker_A | every um sequence of the same topic ?
[34:07] Speaker_B | Mm-hmm .
"[34:12] Speaker_B | Within th within the topic , so like topic we had to when you say topic , you mean like just like from from a beginning to end point , like within one meeting there are several topics ?"
"[34:22] Speaker_A | Yes , but across meetings um there will be the same topic several times ."
"[34:28] Speaker_B | But we don't have that information anywhere , do we ?"
[34:31] Speaker_A | Ah . It wasn okay . I thought that was what you were doing .
"[34:35] Speaker_D | Well , um when it splits the topics up , it does do it on regular words that um that occur . But it doesn't tell you what they are , no ."
[34:44] Speaker_B | But but you you are segmenting .
[34:47] Speaker_D | Hmm .
[34:51] Speaker_D | Yeah .
"[35:00] Speaker_B | But like f for now , like your segmentation is just splitting a meeting up into different blocks ver"
[35:03] Speaker_D | Yeah .
"[35:05] Speaker_D | Yeah , you can't really get any other output ."
[35:10] Speaker_B | Not not from what Colin is doing from what I no . It's only like I'm writing an algorithm that which then tries to also again based on word p occurrence patterns try to link together maybe different ones of those .
"[35:21] Speaker_A | Oh , okay ."
[35:23] Speaker_A | I misunderstood that then .
"[35:28] Speaker_A | So yeah , how would it work ? I mean what would"
[35:32] Speaker_A | um the his information then be useful for in r Rainbow ?
[35:37] Speaker_A | Um I thought the point about that was that we would put um into s um serial categories all the segments of the same topic across meetings .
"[35:49] Speaker_C | Oh no , I li I th I thought something else that we d um we just split I need somewhere to split , and that um splitting at category boundaries um splitting at topic boundaries would a nice thing to do , rather than just splitting somewhere . So yeah , yeah ."
[35:49] Speaker_B | So that yeah .
[35:52] Speaker_A | Okay .
[36:04] Speaker_D | Mm-hmm .
"[36:06] Speaker_D | Yeah , it's supposed to split it into cu coherent topics with the similar information ."
"[36:08] Speaker_A | Yeah , but but then it does okay ."
"[36:11] Speaker_B | Yeah , I'm also a bit b like I'm not a hundred percent sure about Rainbow being the right thing , 'cause it seems that Rainbow does in its structure quite rely on having different examples of the same category sort of in in a way ."
"[36:22] Speaker_C | Yeah , but it I think it should work for just one document , because it it compares between the categories , and if you just have one document um it still can find out which words are informative for that category and which are not . So if you have just one document in each category , and there are a lot of um occurrences of the word the in each one , so this word will be not very informative across the categories . So it should work for one , but I'm not sure if how exactly it it um calculates everything . Uh I think it's not possible to look that up ."
[36:40] Speaker_B | 'Kay .
[36:51] Speaker_A | Mm-hmm .
[36:52] Speaker_D | Hmm .
"[37:01] Speaker_B | You know what , as a byproduct of my L_S_A_ I'll provide um a vocabulary like sort of a dictionary which for each word gives an entropy score entropy score , which just tells you of how much information the presence of a word tells you about which topic it is . Not which category , like I'm not I'm not lumping together separate topic segments into categories . But just like how much this word tells you about wh how likely that w the occurrence of that word makes it that it's a specific segment topic segment . Which is some measure already of how widespread this word is versus how specific f to a certain segment that is . And I'll just provide that , because that's just not much more work than just the usual thing . And then we can see how we can tie that in with the other stuff ."
[37:20] Speaker_A | Mm .
[37:32] Speaker_A | Mm .
[37:49] Speaker_B | So if you um keep on working on Rainbow meanwhile and try to find a way how to tie your Rainbow stuff into
[37:50] Speaker_A | Yep .
[37:58] Speaker_B | some way that we can attach it to a certain time segment .
"[38:09] Speaker_C | Yeah , don't know ."
"[38:14] Speaker_B | It it used is each word completely unique , like sort of does it treat each word , each occurrence of word , as a completely unique event . Or does it , I mean , no , it it has to , I mean , basically the the form of the word is important , right ? We can't just replace the word by an arbitrary string ."
[38:28] Speaker_C | Mm-hmm .
[38:31] Speaker_B | Because it looks if the same word occurs again and stuff .
"[38:45] Speaker_B | What I was thinking is whether if we replace the word by something uniquely id identifiable , then it wouldn't make a different which order it is . But that wouldn't work because it needs the word , because that's all it's working on . It's the word and that looks if that word occurs again and versus how often that word occurs in other context , right ? So we can't attach some type of information to the word , just to the word string itself , like making an underscore , making the time or something , that wouldn't work ."
[38:48] Speaker_C | Mm-hmm . Oh right .
[38:58] Speaker_C | Mm .
[39:02] Speaker_A | Yeah . Mm yeah .
"[39:05] Speaker_C | Alright . Yeah , you you can use um"
"[39:19] Speaker_B | But would it have that in the untruncated version then , like would it s would the output be the untruncated version ? It will probably um no , I don't think it would ."
"[39:24] Speaker_C | Uh probably not . No , no ."
"[39:38] Speaker_C | Yeah , maybe I should try something different and just programme it for myself ."
[39:53] Speaker_C | Mm .
"[39:58] Speaker_B | T I mean , let's just keep on talking meanwhile and I'll try to start that up ."
"[40:04] Speaker_B | It's it's it's really d it it's a very simple thing , but it it basically just"
"[40:08] Speaker_B | does something which tells you how specific a word is . In a sense it's in a it's it's basically just to to a high degree really telling you how r how rare a word is or how common a word is . But uh as as the first step that's probably for for a prototype for next week that's probably not a bad thing , I mean even if it's just that . Even if you just like if you have segments where where lots of rare words occur , highlighted in darker red than segments where all the very common words occur . That's just that's somewhere to start from ."
[40:19] Speaker_C | Mm-hmm .
[40:27] Speaker_D | Hmm . Yeah .
"[40:39] Speaker_B | And it's it's a bit more sophisticated than that , but then de facto it just ends up doing that mostly , from what I figured out ."
"[40:56] Speaker_B | Actually I think I'm not gonna not gonna start that now , because that's probably gonna take too long ."
"[41:05] Speaker_B | if we get it on a word by word basis whatever you do it'll probably appear in a word by word basis , and what you have on a sort of segment but not quite segment base ."
[41:10] Speaker_C | Mm-hmm .
"[41:15] Speaker_A | Yes . Yeah , I mean I haven't really decided on uh how to really get the information out of this now , because um when I have for example um increased speaker overlap , that applies to several turns of course . But I could give um the information about , yeah , how how important this is to each of those segments ."
"[41:42] Speaker_B | 'Kay , what about the following model ? I mean this is a very unscientific way of doing it in some sense , but what if we if we take time as the standard unit for now and sort of like make a massive one segment split super-array . Because everything you're doing can in one way or the other be ti tied down to actual time . So if we if we if for if for each one segment time slot we could attach a value , and then it would be easy to then go back when if we have the time marks here , and re-map that onto onto the length of a segment , you know what I mean ? So if you have for each word say and we know that word starts at this segment and ends at that segment , and you have for like for some time period w the overlap and that period on the F_ ones and that period or something . So you also have a value which can be tied down to a time . And then we could just in m in Matlab or in something just create some massive super-array of"
"[42:36] Speaker_B | of things for each for each like sort of time sampling slot and and calculate a value for this , and once we have this array ,"
"[42:45] Speaker_B | we can go with the script and sort of go for each segment to the starting and end times and say okay , this is from our time segment f here to this time segment there . So we take the some of those and divide them by by the number or something , create the average and put it in as the value for the segment . You know what I mean ?"
"[43:01] Speaker_C | Yeah , but how can we get to know what makes sense as a a function for joining everything together ? Might be difficult to find that out . Yeah ."
[43:09] Speaker_B | Oh .
"[43:22] Speaker_B | We don't have a way of usefully evaluating automatically what's good and what's bad , so it's it's probably always gonna be a question of looking at it and saying okay , like running it with different different factor loadings and seeing okay , this way it works this well and this way it works that well ."
[43:28] Speaker_D | Hmm .
[43:54] Speaker_D | Hmm .
[43:56] Speaker_C | Mm-hmm .
[44:00] Speaker_B | But it probably be more difficult for mapped t to map for you to map it on so for you sort of i
"[44:05] Speaker_A | Yeah sure , but I could then if I if I have um the value for a segment , I would perhaps just give all the"
[44:13] Speaker_A | important wor or mm yeah no .
"[44:17] Speaker_C | You you could always find out how many words there are in an utterance , couldn't you ?"
[44:22] Speaker_A | Yes .
"[44:23] Speaker_B | Yeah , but so you say that inst like you basically say w having an array where each each cell is is one like is o is one word . . And then you would map your information onto individual words ."
[44:32] Speaker_A | Mm-hmm .
"[44:37] Speaker_A | Yeah , I would say that someone have to break it down , aye ?"
[44:40] Speaker_B | Hmm ?
"[44:42] Speaker_A | I would probably somehow have to break it down to to that level , yeah ."
"[44:50] Speaker_A | Yes , sure ."
"[44:53] Speaker_B | 'Kay , and and then we could have like some type of just point in the end where the one scores from the all the individual word cells get multiplied all with like for each utterance or whatever . You have get all multiplied with the same value all the ones that are within that utterance . That's sort of the combination of of the two scores ."
"[45:11] Speaker_A | Yeah , probably somehow it should work that way ."
[45:13] Speaker_C | For example .
[45:14] Speaker_B | And then we'd have to go back again and then put that back into that segment mode here .
[45:19] Speaker_C | Mm .
"[45:20] Speaker_B | So that we because in the end we don't want it on a per word basis , but probably on a per segment base ."
"[45:26] Speaker_A | Yeah , but then okay , but th at that moment it would be better for me to just make it on a per-segment basis right way , and let her adapt it also to the segment basis ."
[45:32] Speaker_D | Hmm .
[45:33] Speaker_C | Mm .
"[45:35] Speaker_B | Oh , yeah yeah , actually that yeah , that's true , so that it's easier if you"
[45:36] Speaker_C | Mm-hmm .
"[45:40] Speaker_B | are able to yeah well , I think that's probably back where we started at this . But you said it wi but you said it's more complicated , because your segments aren't those segments exactly ."
[45:44] Speaker_A | Yeah .
[45:58] Speaker_D | Hmm .
[46:01] Speaker_B | Hmm . And their segments do overlap .
[46:06] Speaker_B | Uh the tho those do or those don't ?
"[46:11] Speaker_A | they're I mean my segments overlap in the same way as theirs do . But sometimes I have um split one of the segments into two segments , but it's easy to match the start and end times to map it to their segments ."
[46:15] Speaker_B | Mm-hmm .
[46:23] Speaker_B | Okay . So you could on their granularity you could on their granularity create a score like for each for each of their segments .
[46:33] Speaker_C | Mm .
"[46:36] Speaker_B | Well I guess I mean for you , if you know for each word , if you find that out , then it has to be possible , because if we know sort of this is going from word to word or it this is going from time to time and then there has to be a way then for you say okay , this concerns these following words , and then just make make a simple mean over them ."
"[46:40] Speaker_C | Yeah , then we sh yeah ."
[46:55] Speaker_B | I think an interesting thing is if we don't combine your two scores in the
"[47:02] Speaker_B | in the X_M_L_ file you had , but if we do that in the software , then we can probably make ways of playing with it in the software and sort of l you know like adapting some sort of control , like playing around with look like it's playing with different weightings for that the utterance-based one versus the word-based one and sort of look at it dynamically . You know what I mean ?"
"[47:23] Speaker_B | Like playing around , sort of figuring out what's the best way of combining them by playing around and looking at the results ."
"[47:26] Speaker_A | Mm-hmm , yeah ."
"[47:29] Speaker_C | We could even yeah , we could even have a look at our different measures , if they um"
[47:37] Speaker_C | come up with the same same kinds of yeah .
[47:37] Speaker_B | Yeah .
"[47:40] Speaker_B | Yeah , we could probably like make a uh um graphic display initially , at least for our experimenting . We'd just place them in different ways and then see how they interact with each other ."
"[47:53] Speaker_B | Okay . Yeah . So do you think y like both of you then can map something onto their segments , like just each of you provide one value , like double value or whatever , like one decimal value or whatever onto onto exactly their segments ."
[48:17] Speaker_C | It's stated from where to where the segments go . It should be uh should be possible .
"[48:21] Speaker_A | Yeah , it's tells you even which words it is ."
"[48:23] Speaker_C | Yeah , so it must should be possible . Yeah ."
[48:31] Speaker_D | Hmm .
"[48:54] Speaker_B | 'Kay , I might just change my order of in which I do things and like forget my latent semantic analysis stuff until the weekend and try to really make sense of the"
"[49:04] Speaker_B | of the NITE data system now , so that maybe as soon as I've understood that we find ways of doing that in within the NITE framework already , so that we don't manually have to parse times and entire things together ."
[49:17] Speaker_C | You mean by matching strings . Or what ?
"[49:28] Speaker_C | Yeah , but what I've done is um a parser , an X_M_L_ parser where you can get the start times ."
[49:34] Speaker_B | Okay .
"[49:35] Speaker_C | So , yeah , that's quite easy , because it's it's an attribute and you just s say that you want the values of those attributes ."
"[49:41] Speaker_B | Mm-hmm . Mm-hmm . So provided that you get your words in the right order , do you think it is an easy task for you to it it's a f relatively feasible task for you to to get just a single value per segment ?"
[49:56] Speaker_B | Okay . And you say you think you're able as well to map onto those segments .
[50:01] Speaker_A | Yep . Should be possible .
"[50:03] Speaker_B | And if you're both able to map into those segments , then we should be able to get one file where we have like whatever two values , value A_ and value B_ both as attributes for"
[50:12] Speaker_C | Mm .
[50:14] Speaker_B | for this .
[50:17] Speaker_B | And that we could load into a prototype and see what types of disp what ways of displaying this information are there .
[50:24] Speaker_A | Yep .
[50:53] Speaker_B | Hmm .
[50:59] Speaker_B | Mm-hmm .
[51:04] Speaker_B | Hmm .
[51:04] Speaker_D | Hmm .
"[51:12] Speaker_B | There's probably also social interaction factors in that there's sometimes just a meeting like if people adapt their F_ zero to each other , then they're sometimes p"
[51:13] Speaker_A | I'll probably look at it .
[51:23] Speaker_B | Yeah .
"[51:26] Speaker_A | Yeah , but it could mess up things quite considerably ."
"[51:29] Speaker_B | Can you not do something like just like not measuring the F_ zero or the amplitude at all , but just like the variance of F_ zero within a certain time frame and like sort of like just have some part for its very low variance with more the same F_ zero and one where there's a lot of more variance . I don't well actually I don't know about that at all ."
"[51:44] Speaker_A | Yeah . But uh ar yeah . But all this is quite , you know , data-intensive . I when I um let the um just calculate the average F_ zero levels , it I think it needed more than half an hour , considerably more than what have half an hour f to delay it for our meetings , because um yeah , m I mean we have seventy five hours per , yeah , av average of six speakers , and they're measured every O_ point O_ one six seconds . And that gives us quite a lot of values ."
[51:50] Speaker_B | Yeah . Sorry .
[52:01] Speaker_B | Mm .
[52:04] Speaker_B | Hmm .
[52:22] Speaker_B | Okay .
"[52:33] Speaker_A | Yeah , what I did at the moment is um I um , yeah , I got the F_ zero values from for each speaker for his headphone , and I only take those um the w uh that were recorded at the time where he was actually speaking . And for those I calculated um the average ."
[52:42] Speaker_B | Mm-hmm .
[52:51] Speaker_B | Mm-hmm .
[52:58] Speaker_A | Zero . So that gave me um now one value per speaker per meeting .
[53:06] Speaker_B | Okay .
"[53:09] Speaker_B | Um so what you would be feeding in would be just like one value per speaker per meeting , so that oka that that's that's your average baseline , okay okay . No yeah , that that makes m yeah , that makes a lot more sense , yeah . So that would show you how much relative to how he sort of how he's performing generally in that meeting relative to that how he's in a specific segment . He or she ."
"[53:14] Speaker_A | No no , that's just the average . No , that i yeah ."
"[53:30] Speaker_A | Yes , I mean I r just uh needed to have this value now to relate um m how yeah ."
[53:35] Speaker_B | Yeah . Yeah . And for you that would be quite easy to translate into those segments .
"[53:42] Speaker_A | Yeah , I think . Yeah ."
[53:48] Speaker_A | Um amusement and so on is yeah .
[53:48] Speaker_C | Because you could take that on ours out maybe . If you take the laughter out and then calculate it .
[53:55] Speaker_C | Mm . Yeah .
[53:57] Speaker_B | Hmm .
[53:58] Speaker_A | Because it's quite funny to have a m male speaking at two hun two hundred um .
"[54:09] Speaker_B | The Castrati corps of the International Computer Science institute . Oh well . I'm afraid I have to go soon . But not quite sure , I mean is there anything more we have to talk about anyway ?"
[54:22] Speaker_C | Not the moment . Maybe if we meet at the weekend .
"[54:28] Speaker_B | Yeah . See , as soon as as soon as I'm halfway through my L_S_A_ like basically as soon as I have the the matrix built , if of the document by word stuff , it's very easy to then calculate for each word a score , and I can just give you those scores and you can do with them whatever you want ."
[54:28] Speaker_C | Oh I don't know .
"[54:45] Speaker_C | So uh no , how about the the prototype . If we want to show him something on Monday , we definite have to work together . Some of us at least have to work together to get it running probably ."
"[54:57] Speaker_B | Yeah , I think Colin , Dave and me will actually work on on the Java stuff , and it and we'll just see whatever you whatever you supply us , we'll try to tie in and visualise in some way or another ."
[55:06] Speaker_C | Alright .
[55:09] Speaker_B | Um I'll ask Jonathan if we can postpone the meeting to one o'clock . So that would give us a chance of meeting in for an hour before that to discuss the questions that we had .
"[55:15] Speaker_D | Yeah , that sounds like an idea ."
"[55:23] Speaker_D | Yeah . Yeah , just send us an email and tell us what's happening ."
"[55:26] Speaker_B | Yeah , I haven't gotten like sort of my confirmation that w Wednesday is fine . I'm not sure if I'm supposed to expect a confirmation for my confirmation from him now or but I'll just email him again and s ask him if we can maybe make it one sorry , we said twelve and I'm asking if he can make one . This is a bit frustrating at the moment , this project , isn't it ? It's so like difficult to to get to the point where you understand enough to really feel that . I don't know , I'm not feeling that I'm really working at the moment , I'm more just trying to make sense of everything . And it's a bit too far into the meeting for that , and into the project for that ."
[55:56] Speaker_A | Mm-hmm .
[56:08] Speaker_B | Hmm .
"[56:12] Speaker_B | I guess as soon as we have a framework in the w in the type of the prototype where like sort of each of us can tie in their stuff and see what it l how how it looks like and how it performs , you know . That probably makes it a lot easier then , but it's sort of it's a boot-strapping problem , like for the prototype we need some type of data , but to develop the data it would be a lot easier to to have the prototype ."
[56:30] Speaker_A | Yeah .
"[56:32] Speaker_B | Anyway , I gotta go ."
"[56:32] Speaker_A | Yeah . So I mean you will be happy with some data , even if it doesn't make much sense ."
"[56:33] Speaker_C | Yeah , me too ."
[56:34] Speaker_C | .. .
[56:36] Speaker_B | Hmm ?
"[56:37] Speaker_B | Yes , but if it's if it's in a form which is easy to read in at the moment , that would be fine . Sort of like if basically if we have something like this segments file , but for each of you like just have one attribute . I think it's really easy if we don't merge them before-hand , but if we let them if we combine them in the prototype or don't at the moment , because then we can easily d display them individually , c contrast them to each other and play around with how y to combine them ."
[56:56] Speaker_A | Try uh try yeah . Mm-hmm .
"[57:05] Speaker_B | Exactly , yeah . Yeah . And I mean computationally multiplying two integers or doubles or whatever shouldn't be the thing that slows us down ."
"[57:12] Speaker_A | Yeah , if it's already on segments base , that's not too much ."
[57:15] Speaker_B | Yeah .
[57:17] Speaker_C | Okay .
[57:18] Speaker_B | Alright .
[57:21] Speaker_D | Right .
