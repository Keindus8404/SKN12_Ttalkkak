[00:03] Speaker_E | 'Kay .
[00:05] Speaker_E | Gosh .
[00:05] Speaker_A | Okay .
[00:10] Speaker_E | 'Kay .
[00:11] Speaker_A | Does anyone want to see uh Steve's feedback from the specification ?
[00:16] Speaker_E | Is there much more in it than he d
[00:16] Speaker_D | I I dry-read it the last time . .
[00:18] Speaker_A | Right .
[00:18] Speaker_E | Is there much more in it than he said yesterday ?
[00:22] Speaker_E | Mm .
[00:25] Speaker_E | Hmm . Hmm ?
"[00:28] Speaker_A | Like duplication of effort and stuff , and um yeah , he was saying that we should maybe uh think about having a prototype for week six , which is next week . Yeah ."
[00:38] Speaker_D | Next week .
[00:42] Speaker_A | So we should probably prioritize our packages .
[00:56] Speaker_A | Mm .
[01:18] Speaker_B | Yeah .
[01:19] Speaker_A | Yeah .
"[01:32] Speaker_E | Oh yeah , um yeah . No . But also I might like the the similarity thing , like my just my matrix itself for my stuff , I c I I think I can do that fairly quickly because I have the algorithms . Yeah , I think today's meeting is really the one where we where we sort of settle down the data structure and as soon as we have that , uh probably like after today's meeting , we then actually need to"
[01:33] Speaker_D | Yeah .
[01:49] Speaker_D | Yeah .
[01:54] Speaker_E | well go back first of all and look at NITE X_M_L_ to see in how far that that which we want is compatible with that which NITE X_M_L_ offers us . And then just sort of everyone make sure everyone understand the interface .
[02:01] Speaker_A | Yeah .
"[02:08] Speaker_E | So I think if today we decide on what data we wanna have now , and and later , maybe even today , we go and look at NITE X_M_L_ or some of us look at NITE X_M_L_ in a bit more detail , just trying to make some sense of that code and see how does the representation work in their system . And then sort of with that knowledge we should be able to then say okay , that type of NITE X_M_L_ data we wanna load into it , and this is how everyone can access it , and then we should be able to go from there ."
"[02:35] Speaker_A | Hmm . Has has anyone actually looked at the Java code for the , huh ? Hmm ."
[02:39] Speaker_E | No .
[02:40] Speaker_D | No .
"[02:41] Speaker_E | I've looked looked at the documentation and n like seen enough to make me think that we want to use the NITE X_M_L_ framework because um they have a good a event model that synchronizes sort of the data and and every display element . So that takes a lot of work away from us . Sort of that would be a reason for staying within their framework and using their general classes . But beyond that I haven't looked at it at all , which is something we should really do . Who actually like for this whole discussion I mean , who of us is doing stuff that is happening on-line and who of us is doing stuff that's happening off-line ? Like my data is coming c"
"[03:06] Speaker_A | Yeah , I think so ."
[03:30] Speaker_E | Hmm ?
[03:31] Speaker_C | The basic word importance is off-line as well . The combined measure might not be if we want to wait what the user has typed in into the search .
[03:33] Speaker_E | Yeah .
[03:38] Speaker_E | Okay .
[03:40] Speaker_E | Okay .
"[03:42] Speaker_D | Uh mine's gonna be mostly using the off-line . But the actual stuff it's doing will be on-line . But it won't be very um processor intensive or memory intensive , I don't think ."
[03:48] Speaker_E | 'Kay .
"[03:51] Speaker_E | So basically apart from the display module , the i the display itself , we don't have an extremely high degree of interaction between sort of our modules that create the stuff and and the interface , so the interface is mainly while it's running just working on data that's just loaded from a file , I guess ."
"[04:12] Speaker_A | Yeah , I I don't know about the search functionality , that might be online . Depends how it's gonna work ."
[04:12] Speaker_B | Hmm .
"[04:17] Speaker_E | Yeah , I know . Th Yeah , the search is I guess the search is sort of a strange beast anyway because for the search we're leaving the NITE X_M_L_ framework . Um but that's still sort of that's good . That means that at least like we don't have the type of situation where somebody has to do like a billion calculations on on data on-line . 'Cause that would make it a lot more like that would mean that our interface for the data would have to be a lot more careful about how it performs and and everything . And nobody is modifying that data at at on-line time at all it seems . Nobody's making any changes to the actual data on-line ."
[04:25] Speaker_A | Yeah .
[04:54] Speaker_D | Don't think so .
"[04:55] Speaker_E | So that's actually making it a lot easier . That basically means our browser really is a viewer mostly , which isn't doing much with the data except for sort of selecting a piece piece of it and and displaying it ."
[04:57] Speaker_D | Yeah .
[05:10] Speaker_D | Are we still gonna go for dumping it into a database ? Are we still gonna dump it into a database ?
[05:13] Speaker_E | Hmm ?
"[05:16] Speaker_E | Well some parts relevant for the search , yes . I'd say so ."
"[05:20] Speaker_D | 'Cause if we are , I reckon we should all read our classes out of the database . It'll be so much easier ."
[05:25] Speaker_E | Hmm ?
"[05:26] Speaker_D | Well if we're gonna dump the part of it into a database anyway , we might as well dump all the fields we want into the database , calculate everything from there . Then we don't even have to worry that much about the underlying X_M_L_ representation . We can just query it ."
"[05:43] Speaker_E | Yeah , but nobody of us is doing much of searching from the data in the on-line stage ."
"[05:48] Speaker_E | And for all together , like the display itself , I think we are easier if we if it's sitting on the X_M_L_ than if it's sitting on the S_Q_L_ stuff , because if it's sitting on the X_M_L_ , we have the the NITE X_M_L_ framework with all its functionality for synchronizing through all the different levels whenever there's a change , whenever something's moving forward and stuff . And we can just more or less look at their code , like how their player moves forward , and how that moving forward is represented in different windows and stuff . So I think in the actual browser itself I don't wanna sit on the S_Q_L_ if we can sit on the X_M_L_ because sitting on the X_M_L_ we have all we have so much help . And for y for like the p the calculations that we're doing apart from the search , it seems that everyone needs some special representations anyway ."
"[06:33] Speaker_D | Well if we're gonna do that , we should try and store everything in in an X_M_L_ format as well ."
"[06:40] Speaker_E | You mean our results ? Yeah , in in the NITE X_M_L_ X_M_L_ format , so with their time stamps and stuff , so that it's easy to to tie together st things ."
[06:41] Speaker_D | Yeah .
[06:46] Speaker_B | Yes .
[06:48] Speaker_D | Yeah .
"[07:23] Speaker_E | If we if we do it this way like we f we have to discuss that if we do it this way , then we should probably find some abstraction model , so that the interface in the sense like deals with it as if it's same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting , you know what I mean ? And that's probably stuff that we have to sort of like process twice then . Like for example that like the summary of a meeting within the whole meeting corpus or meeting series y is meeting series a good word for that ? I don't really know what how to call it . You know what I mean , like not not the whole corpus , but every meeting that has to do with one topic . Um so in in the meeting se series so that a summary for a meeting within the meeting series , are sort of"
[07:40] Speaker_A | Mm-hmm .
[07:41] Speaker_B | Hmm yes .
[07:54] Speaker_B | Hmm .
"[07:59] Speaker_A | Yeah , that makes sense ."
"[08:14] Speaker_D | Well we don't even need to do that , 'cause if we got our information density calculated off-line , so all we do is treat the whole lot as one massive document . I mean they'll it's not gonna be so big that we can't load in a information density for every utterance . And we can just summarise based on that ."
"[08:31] Speaker_B | I I thought we would just have like um one big summary um with all the uh different importance levels um displayed on it . And depending on what our um zoom level is , we just display a part of it ."
[08:51] Speaker_B | And we would have one very big thing off-line . And from that we would just select what we are displaying .
[08:58] Speaker_E | And just have different like fine-grainedness levels sort of .
[09:02] Speaker_B | Yes . So for example you would um give a high value to those um sequences you want to display in the meeting series summary . And you just cut off .
[09:08] Speaker_E | Mm .
"[09:11] Speaker_E | 'Kay . So the only thing that yeah , so the only thing that would happen basically if I double-click let's say from the whole meeting series on a single meeting , is that the zoom level changes . Like the th the start and the end position changes and the zoom level changes ."
"[09:26] Speaker_B | That was what I sh I thought , yeah . I thought ."
[09:27] Speaker_D | I think you can do it on-line .
[09:28] Speaker_E | I I thought we couldn't do that . Like I was under the impression that we couldn't do that because we couldn't load the data for all that .
[09:38] Speaker_A | Hmm .
"[09:38] Speaker_D | I don't think there's really much point in doing like that when it's just gonna feed off in the end the information density measure basically . And that's all calculated off-line . So what you're really doing is sorting a list , is the p computationally hard part of it ."
"[09:58] Speaker_D | Well like the ideas we're calculating are information density all off-line first for every utterance in the whole corpus , right ? So what you do is you say if you're looking at a series of meetings , you just say well our whole document comprises of all these stuck together . And then all you have to do is sort them by j information density . Like maybe weighted with the search terms , and then extract them . I don't think it's too slow to do on-line , to be honest ."
[10:05] Speaker_E | Mm-hmm . Mm-hmm .
[10:13] Speaker_E | Mm-hmm .
[10:17] Speaker_E | Mm-hmm .
[10:20] Speaker_E | Okay .
"[10:26] Speaker_E | Okay . I wa I was just worried about the total memory complexity of it . But I I completely admit , I mean , I just sort of like th took that from some thing that Jonathan once said about not loading everything . But maybe I was just wrong about it . How many utterances w"
"[10:51] Speaker_E | Yeah , and I w yeah . Yeah . Yeah . Yeah . So what we have is we would have a word ."
[10:54] Speaker_D | Yeah .
[10:55] Speaker_A | Hmm .
[11:02] Speaker_E | Like we would have words with some priority levels . And they would basically be because even the selection would would the summaries automatically feed from just how prioritized an individual word or how indiv uh prioritized an individual utterance is ? Or i are the summaries sort of refined from it and made by a machine to make sentences and stuff ? Or are they just sort of taking out the words with the highest priority and then the words of the second highest priority ?
"[11:25] Speaker_D | Well , on the utterance level I was thinking . So the utterances with the highest like mean information density ."
[11:28] Speaker_E | And the u okay .
"[11:32] Speaker_E | Are we doing it on th the whole thing on the utterance level ? Or are we doing it on word level , like the information density calculation ?"
"[11:35] Speaker_D | Well the trouble with doing it on the word level is if you want the audio to synch up , you've got no way of getting in and extracting just that word . I mean it's impossible ."
"[11:43] Speaker_E | We I think we have start and end times for words actually , but it's yeah , but it m it might s but it might sound crazy in the player . We should really maybe we can do that together at some point today that we check out how the player works . But there's maybe some merit in altogether doing it on an utterance level in the end ."
"[11:45] Speaker_D | For every single word ? Oh , okay ."
[11:47] Speaker_C | Yeah .
[11:50] Speaker_D | Yeah .
[11:53] Speaker_D | I don't think that will do it . We'll have to buffer it .
"[11:55] Speaker_B | Um I r I I'm getting quite lost um at the moment because um w what's um our difference between the um se um uh the importance measure and the skimming ? I mean , do we do both or is it the same thing ?"
[12:14] Speaker_D | Well the skimming's gonna use the importance .
[12:16] Speaker_E | Yeah .
[12:17] Speaker_B | Okay .
[12:18] Speaker_D | But like at first it's just gonna be I_D_F_ .
"[12:24] Speaker_D | Well mostly skimming , yeah ."
[12:42] Speaker_B | Yeah .
"[12:46] Speaker_E | Yeah , r"
"[12:46] Speaker_B | Yeah right , isn't that the skimming ? Isn't that the skimming ?"
[12:48] Speaker_E | Hmm ?
"[12:49] Speaker_E | Oh yeah , f it's just like there there's like audio skimming and there's displayed skimming ."
"[12:54] Speaker_B | Yeah , but it use the same data ."
"[12:57] Speaker_E | Yeah . Ma maybe there's some merit of going altogether for utterance level and not even bother to calculate I mean if you have to do it internally , then you can do it . But maybe like not even store the importance levels for individual words and just sort of rank utterances as a whole ."
[12:57] Speaker_D | Yeah .
"[13:12] Speaker_D | Well the nice thing about that is it will automatically be in sentences . Well more or less . So it will make more sense , and if you get just extract words ."
[13:15] Speaker_E | Hmm ?
[13:17] Speaker_E | Yeah .
"[13:19] Speaker_E | 'Cause it it might be better skimming and less memory required at the same time . And I mean if you if you know how to do it for individual words , then you can just in the worst case , if you can't find anything else , just sort of make the mean of the words over the utterance . You know what I mean ?"
"[13:36] Speaker_E | Well what's the smallest chunk at the moment you're thinking of of assigning an importance measure to , is it a word or is it an utterance ?"
[13:42] Speaker_C | Uh I thought about words .
[13:44] Speaker_E | So we're thinking of like maybe just storing it on a per utterance level .
"[13:52] Speaker_E | Because it's it's less stuff to store probably for Dave in the in the audio playing . And for in the display it's probably better if you have whole utterances than I don't know , like what it's like if you just take single words out of utterances . That probably doesn't make any sense at all , whereas if you just uh show important utterances but the utterance as a whole it makes more sense . So it doesn't actually make a difference for your algorithm , 'cause it just means that if you're working on a word level , then we just mean it over the utterance ."
[13:53] Speaker_C | Mm .
[14:02] Speaker_B | Yeah .
[14:06] Speaker_D | Yeah .
"[14:15] Speaker_B | And , yeah , I think we also thought about combining that measure with um the measures I get from um s uh hot-spots and so on . So that would also be on utterance level , I think . I think ."
[14:15] Speaker_C | Mm okay .
"[14:29] Speaker_E | Oh so that's good anyway then , yeah . Because that makes it a lot easier than to t put it on utterance level ."
[14:30] Speaker_D | I see it .
[14:32] Speaker_D | But it'll need to be calculated at word level though because otherwise there won't be enough occurrences of the terms to make any meaningful sense .
"[14:39] Speaker_E | Oh yeah . No but I mean like how how Jasmine does it internally I don't know , but it's probably , yeah , you probably have to work on word levels for importance . But there should be ways of easily going from a word level to an utterance level . Okay ."
[14:44] Speaker_D | Yeah .
"[14:49] Speaker_D | Yeah , I reckon you can just mean it over the sentence ."
"[14:50] Speaker_C | Yeah , but how about those words which don't carry any meaning at all , the um and uhs and something like that ."
"[15:00] Speaker_E | Yeah , prob"
[15:01] Speaker_D | I think we should filter them .
[15:06] Speaker_E | Hmm .
[15:17] Speaker_D | Maybe we should have like um a cut-off . So it a w word only gets a value if it's above a certain threshold . So anything that has less than say nought point five importance gets assigned to zero .
[15:30] Speaker_C | Alright .
"[15:31] Speaker_E | Well we do a pre-filtering of sort of the whole thing , sort of like but that , like the problem with that is it's easy to do in the text level . But that would mean it would still play the uh in your audio , unless we sort of also store what pieces we cut out for the audio ."
"[15:33] Speaker_D | Yeah , that's the other th"
[15:39] Speaker_D | Yeah .
"[15:48] Speaker_E | Yeah . I think before we can like answer that specific question how we c deal with that , it's probably good for us to look at what the audio player is capable of doing ."
[15:58] Speaker_D | I think we'll have to buffer the audio . But I don't think it will be very hard . I think it would be like an hour or two's work .
[16:00] Speaker_E | Yes .
[16:06] Speaker_D | Like just build an another f wave file essentially .
"[16:10] Speaker_A | Yeah , you just concatenate them together ."
"[16:11] Speaker_E | But yeah , but not but not stored on the hard disk and then loaded in , but loaded in directly from memory ."
"[16:16] Speaker_D | In memory , yeah . So just like unp there's bound to be like a media wave object or something like that . And just build one in memory ."
"[16:22] Speaker_E | But it's probably a stream if it exists in Java , it would be probably some binary stream going in of some type . Okay , yeah ."
"[16:35] Speaker_E | Okay . Okay , so I mean so that means that there's probably , even if you go on an per utterance level , there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all , and that maybe also for the audio we'd have to do . So let's say we play the whole au phrase , but then in addition to that , we have some information that says minus that part of something . That's okay , that we can do ."
"[16:56] Speaker_D | Well what I think I might try and build is basically a class that you just feed it a linked list of um different wave-forms , and it will just string them all together with maybe , I don't know , tenth of a second silence in between each one or something like that ."
"[17:12] Speaker_E | Yeah , maybe even I mean that's sort of that depends on how how advanced we get . If maybe if we realise that there's massive differences in in gain or in something , you can probably just make some simple simple normalization , but that really depends on how much time we have and and how much is necessary . Yeah , if like I d I don't know anything about audio and I have never seen the player . So if you find that the player accepts some n input from memory , and if it's easy to do , then I guess that's that's fairly doable . So but that means in the general structure we're actually quite lucky , so we we have we load into memory for the whole series of meetings just the utterances and rankings for the utterances and some information probably that says , well , the I guess that goes with the utterance , who's speaking ."
"[17:21] Speaker_D | Normalise it , yeah ."
"[17:52] Speaker_D | Oh yeah , yeah , we'll need that ."
"[17:53] Speaker_B | Yes , sure ."
[17:53] Speaker_E | Because then we can also do the display about who's speaking .
[17:56] Speaker_D | We also really wanna be able to search by who's speaking as well .
[18:00] Speaker_E | Yeah .
"[18:12] Speaker_D | It doesn't matter , 'cause all the calculation's done off-line ."
"[18:20] Speaker_E | The other hand , I mean it shouldn't be like should be like fifty mega-byte in RAM or something , it shouldn't be massive , should it ? Actually fifty hundred megabyte is quite big in RAM ."
[18:25] Speaker_A | Hmm .
"[18:35] Speaker_E | Just thinking , what's the simp so"
"[18:40] Speaker_E | We do get an error message with the project if we load everything into the project with all the data they load . So we know that doesn't work . So our hope is essentially that we load less into it . What's this lazy loading thing , somebody explain lazy loading to me ."
[18:51] Speaker_B | Yes .
[18:51] Speaker_A | Yeah .
[18:54] Speaker_A | It just means it loads on demand . It only loads when it needs a particular type of file . Like when it's being accessed .
"[19:20] Speaker_A | Yeah , I think that's the idea , it just loads the particular ones it needs ."
[19:27] Speaker_A | But if you were doing a search over the whole corpus you'd have to load them all .
"[19:29] Speaker_E | Yeah , but yeah , but um it uh it it failed right when you load it , right , the NITE X_M_L_ kit , so that's interesting ."
"[19:35] Speaker_B | Yes , right ."
[19:39] Speaker_A | Hmm .
"[19:40] Speaker_B | Oops , it does . So I define baseline and what it loads ? For example it loads all the utterances and so on , but it doesn't load um the discourse acts and for example not the and what's what else there ? Not the summaries . It only loads those on demand ."
[19:52] Speaker_E | Hmm .
"[20:03] Speaker_E | Let's check that out . Um I'll p I'll probably ask Jonathan about it . So alternatively , if we realise we can't do the whole thing in one go , we can probably just process some sort of meta-data , you know what I mean , like sort of sort of for the whole series"
[20:21] Speaker_E | chunks representing the individual meetings or some
"[20:27] Speaker_E | Like something that represents the whole series in in a v in a structure very similar to the structure in which we represent individual um meetings , but with data sort of always combined from the whole series . so instead of having an single utterance that we display , it would probably be like that would be representing a whole um topic , a segment in a meeting ."
[20:53] Speaker_E | And sort of so that wi using the same data st
[20:54] Speaker_B | Y you mean that you um basically split up th the big thing into um different summaries . For example that you have a very um top-level um summary and a separate file for for each level .
"[21:12] Speaker_E | Uh I'm I'm thinking of in a sense of like creating a virtual a virtual meeting out of the whole meeting series , sort of ."
[21:18] Speaker_D | That's easy . You just like create a new X_M_L_ document in memory .
[21:42] Speaker_B | Mm-hmm .
[22:02] Speaker_A | Mm .
"[22:04] Speaker_E | 'Cause also like even if we maybe this whole like maybe I'm worrying too much about the whole series in one thing display , because actually I mean probably users wouldn't view that one too often ."
"[22:16] Speaker_D | I don't think it's really that much of a problem because if it's too big , what we can do is just well all the off-line stuff doesn't really matter . And all we can do is just process a bit at a time . Like for summarisation , say we wanted a hundred utterances in the summary , just look at the meeting , take the top one hundred utterances in each other meeting . If it scores higher than the ones already in the summary so far , just replace them . And then you only have to process one meeting at a time ."
"[22:43] Speaker_E | Yeah , but I'm I'm still worried . Like for example for the display , if you actually if you want a display uh like for the whole series , the information density levels based on and and the f and the only granularity you have is individual utterances , that means you have to through every single utterance in a series of seventy hours of meetings ."
"[23:03] Speaker_D | Okay , so maybe we should build a b store a mean measure for the segments and meetings as well ?"
"[23:09] Speaker_E | Yeah . Yeah , and if you make that structurally very similar to the the le like one level down , like the way how we uh store individual utterances and stuff , then maybe we can more or less use the same code and just make a few ifs and stuff ."
"[23:25] Speaker_E | Yeah , so so but still so in in general we're having we're having utterances"
[23:31] Speaker_E | and they have a score .
"[23:35] Speaker_E | And that's as much as we really need . And of cou and they also have a time a time information of course . Hmm ? And a and a s and a speaker information , yeah ."
[23:42] Speaker_D | And speaker . Speaker and um topic segmenting we'll need as well .
[23:52] Speaker_D | Yeah .
[23:58] Speaker_E | Yeah .
[24:14] Speaker_D | Yeah .
"[24:23] Speaker_E | but that that's enough data for the skimming and the the searching , so what the searching does is the searching leaves the whole framework , goes to the S_Q_L_ database and gets like basically in the end gets just a time marker for where that is , like that utterance that we are concerned with . And then we have to find I'm sure there's some way in in NITE X_M_L_ to just say set position to that time mark . And then it shifts the whole frame and it alerts every single element of the display and the display updates ."
"[24:26] Speaker_D | Yeah , I think so ."
[24:50] Speaker_A | Hmm .
"[24:51] Speaker_A | Yeah , we do not want it in to develop a little tree display as well for multiple results ."
"[24:57] Speaker_A | Yeah , but that'd be quite easy to do ."
[25:03] Speaker_A | You just need to find the time stamp .
[25:10] Speaker_A | Yeah .
"[25:40] Speaker_E | It's the same thing if like whether you play and it moves forward or whether you jump to a position through search , it's essentially for all the window handling , it's the same event . It's only that the event gets triggered by the search routine which sort of push that into NITE X_M_L_ and says please go there now ."
[25:49] Speaker_A | Yeah .
[25:57] Speaker_D | So we should basically make our own X_M_L_ document in memory
[26:03] Speaker_D | that everyone's um
"[26:07] Speaker_D | module changes that , rather than the underlying data . And then have that X_M_L_ uh NITE X_M_L_ document tied to the interface ."
"[26:19] Speaker_D | Well , you can make it in a file if you want ."
[26:22] Speaker_E | I mean like the information is coming from off-line .
"[26:28] Speaker_E | So we probably we don't even have to change the utterance document , right , because the whole way , like the whole beauty of the NITE X_M_L_ is that it ties together lots of different files . So we can just create an additional X_M_L_ file which for every utterance like the utterances have I_D_s I presume , some references . So we just we tie uh p just a very short X_M_L_ file , which it's the only information it has that has whatever a number for for the um weight , for the information density , and we just tie that to the existing utterances and tie them to the existing speaker changes ."
[26:43] Speaker_D | Mm-hmm .
[26:44] Speaker_B | Yes .
[27:00] Speaker_C | But there is no I_D_ for an utterance I think . It's just for individual words . So how do we do that then ? We for utterances as well .
[27:13] Speaker_C | I think it's just for one
"[27:18] Speaker_A | Yeah , I think I think those segments for each utterance are split up ."
[27:23] Speaker_C | Yeah .
[27:24] Speaker_A | Think so .
[27:26] Speaker_E | Well otherwise we probably have to go over it and like add some integer that we just increment from top to bottom sort of to every utterance as an as an I_D_ some type . Or un or try to understand how NITE X_M_L_ I_D_s work and maybe there's some special route we have to follow when we use these I_D_s . It's alm hmm ?
"[27:43] Speaker_A | Yeah , I'm pretty sure it's already there . Pretty sure that's already there . The the utterances are numbered ."
"[27:50] Speaker_E | Yeah , the the girl said the utterances themselves are not numbered at the moment ."
"[27:54] Speaker_C | Uh I'm not quite sure , I have only seen that the uh the individual words have got an I_D_ ."
[27:55] Speaker_E | Okay . Okay . Okay . Yeah . So I guess that would be solvable if not .
[28:03] Speaker_C | Yeah . You always could have a look at the time stamps and then take the ones that uh belong together to form an utterance .
[28:07] Speaker_E | Mm-hmm .
"[28:13] Speaker_B | No , I I think we would just take the segments that are already that were Yeah , there's um this segments file . Um you know , the X_M_L_ segments ."
[28:13] Speaker_E | Sorry ?
"[28:18] Speaker_C | Yeah , if they are already , there's it's easy but it would be possible ."
[28:20] Speaker_E | Okay .
[28:22] Speaker_E | Okay .
[28:23] Speaker_C | Uh yeah . Okay .
[28:24] Speaker_A | Hmm .
[28:26] Speaker_E | Is that a board marker pen actually ?
[28:27] Speaker_B | Oh .
[28:31] Speaker_B | That I don't know .
"[28:31] Speaker_E | Oh . That's just so like to make a list of all this stuff , or we probably can somebody can do it on paper ."
"[28:31] Speaker_A | Yeah , I think so ."
"[28:39] Speaker_E | All these fancy pens . So what so the stuff we have we have utterances and speakers and weights for utterances . So for for every utterance sort of like the utterance has a speaker and a weight which is coming from outside . Or we just tie it to it . And there is segments , which hmm ?"
"[29:02] Speaker_D | They are utterances , aren't they ? The segments are utterances , aren't they ? Yeah ."
"[29:05] Speaker_A | Ye that's the impression I get , yeah ."
"[29:07] Speaker_E | Oh , so sorry um . Uh topic s topic segments I meant . Like they are they are a super-unit . So so the utterances are tied to topic segments ."
"[29:10] Speaker_D | Alright , okay ."
[29:11] Speaker_B | Mm-hmm .
[29:12] Speaker_A | Oh .
"[29:21] Speaker_E | And if the time stamps are on a word level , then we b somehow have to extract time stamps for utterances where they start ."
"[29:28] Speaker_B | There there are time stamps um for , well , segments um and for th um segments is for example when when you look at the data , what is displayed in one line ."
"[29:28] Speaker_D | Well , that's easy ."
[29:34] Speaker_E | W what segments now ?
[29:43] Speaker_A | Hmm .
[29:43] Speaker_B | What when when you look at it in the hmm ?
[29:47] Speaker_A | Mm .
"[29:49] Speaker_D | Well it's close enough , isn't it ? It may not be exact every time , but it's a so sort of size we're looking for ."
[29:52] Speaker_B | Um for ex um I I compared it with what I did for the pause um duration extraction . Um and basically it's uh words that are uttered in a sequence without pauses . But sometimes um however there are um short pauses in it and they're indicated by square brackets pause or something in the data .
[29:58] Speaker_E | Mm-hmm . Mm-hmm .
[30:12] Speaker_E | What so that's Oh . But that's one o one segment or is that two segments then ?
[30:14] Speaker_A | Right .
[30:20] Speaker_B | Um someti uh but uh the annotators decided what was one segment and what wasn't .
[30:23] Speaker_E | Yeah .
"[30:26] Speaker_E | Okay . Okay . So but but generally utterances is that which we just called uh sorry , segments is that which we just called utterances now . Like it's it's the sa it's sort of like one person's contribution at a time sort of thingy dingy ."
[30:35] Speaker_B | I think so .
"[30:36] Speaker_D | Yeah , yeah ."
[30:40] Speaker_A | Okay .
"[30:41] Speaker_E | Okay , so yeah , so we have those , and and then we have some f field somewhere else which has"
[30:48] Speaker_E | topics .
"[30:50] Speaker_A | Topics , yeah ."
"[30:51] Speaker_E | Yeah , and and a topic's basically they are just on the I_D_ , probably with a start time or something , and and the utterances referenced to those topics I guess . So the topics don't contain any redundant thing of like showing the whole topic again , but they just sort of say a number and where they start and where they finish . And the utterances then say which topic they belong to ."
"[30:58] Speaker_A | Yeah , I think that's the right one ."
"[31:10] Speaker_B | Yeah , but um I think for some annotations um an uttera ca utterance can have several um types . For example for the dialogue acts and so on ."
[31:10] Speaker_A | Hmm .
"[31:24] Speaker_E | Yeah . No . But I was thinking of the topic segmentation now and and f for that there would only be one , right , because it's sort of like it's just a time window ."
[31:27] Speaker_A | Hmm .
"[31:31] Speaker_B | Yeah . Should be , yeah ."
[31:32] Speaker_A | Mm-hmm .
[31:33] Speaker_E | Yeah .
"[31:36] Speaker_E | So if this lazy loading works , then this should definitely fit into I mean not memory then because it wouldn't all be in memory at the same time . So if we just have those sort of that information like a long list of all the utterances slash segments and like short or smaller lists which give weight to them ."
[32:03] Speaker_D | Yeah .
[32:11] Speaker_D | But why don't we just write it as a new X_M_L_ file ? Can NITE handle just loading arbitrary uh new like attributes and stuff ?
"[32:21] Speaker_D | I mean , I would have thought they'd make it able to ."
"[32:23] Speaker_E | Yeah , I thought that was the whole beauty that like you can just make a new X_M_L_ file and sort of tie that to the other and and it tre"
[32:24] Speaker_D | Yeah .
[32:29] Speaker_D | So why do we need to have two X_M_L_ trees in memory at once ?
"[32:32] Speaker_E | Oh yeah . So no , I didn't I didn't mean tree . No . No . I meant just like handling two different files internally . Sort of c I was just thinking you know like if if the overhead for having the same amount of data coming from two d files instead of from one file is massive"
"[32:46] Speaker_E | then it would probably be for us easy to just like off-line put the the weight into into the file that has the segments , uh yeah , segments slash utterances already . But that we can figure out I mean if it's going horrendously wrong ."
"[33:00] Speaker_D | The other thing is that would mean we'd be using their parser as well , which means we wouldn't have to parse anything , which be quite nice . 'Cause their parser is probably much faster than anything we've come up with anyway ."
[33:06] Speaker_E | Yeah .
"[33:10] Speaker_E | Yeah . Yeah , no , we'd we'd be completely using like the whole infrastructure and basically just I mean the main difference really between our project and theirs really is that we load a different part of the data . But otherwise we're doing it the same way that they are doing it . So we just we're sort of running different types of queries on it . We in a sense we I think we are running queries , it's not just about um what we load and what we don't load , but we're l running queries in the sense that we dynamically select by by weights , don't we ? That we have to check how fast that is , like to say give us all the ones that whether that works with their query language , whether that's too many results and whether we shou"
[33:46] Speaker_A | Mm .
"[33:50] Speaker_E | You know , if 'cause if it i let's say I mean if if their query language is strange and if it would return b ten million results and it can't handle it , then we can just write our individual components in the way that they know which what the threshold is . So they still get all the data and just they internally say oh no , this is less than three and I'm not gonna display it or something ."
"[34:11] Speaker_D | Yeah , I mean we can process it in chunks if it gets too big basically . We can just process it all in chunks if it gets too big to load it into memory ."
[34:14] Speaker_E | Hmm ?
"[34:17] Speaker_E | Yeah . No . I'm just thinking for this whole thing of like a different level , sort of cutting out different different pieces , whether we do that through a query where we say give us everything that's ab above this and this weight , or whether we skip the same infrastructure , but every individual module like the player and the display say like they still get sort of all the different utterances , uh all the different pieces , but they say oh , this piece I leave out , because it's below the current threshold level ."
[34:19] Speaker_A | Hmm .
[34:42] Speaker_D | I think we probably want to store Sorry . I think we probably want to store um a hierarchical information density as well . So like an informan mation density score for each meeting and each topic segment . 'Cause otherwise we'd be recalculating the same thing over and over and over again .
"[35:01] Speaker_A | Yeah , that'd be much more efficient to do that . Yeah ."
[35:02] Speaker_D | Yeah .
[35:04] Speaker_D | And that will obviously make it much easier to display .
[35:08] Speaker_E | When do we need the one for the meet
"[35:13] Speaker_E | Okay . Yeah , I guess for the so when we have the display , will we display the whole series . Then if we have for the individual topic segments within the meetings if we have ready calculated disp um measures , then we don't have to sort of extract that data from the individual utterances . Yeah , and that's also fairly easy to store along with our segments , isn't it . For the segments , are we extracting some type of title for them that we craft with some fancy algorithm or manually or we're just taking the single most highly valued key-word utterance for the segment heading ?"
"[35:25] Speaker_D | Yeah , exactly ."
[35:30] Speaker_D | Yeah .
"[35:44] Speaker_D | Well , we can start off"
[35:47] Speaker_D | like that . Well I was gonna start off I've v got sort of half-way through implementing one that does just I_D_F_ .
[35:53] Speaker_E | Hmm .
[35:55] Speaker_D | And then just I can change that to work on whatever .
[35:58] Speaker_E | Hmm . It's probably like in in the end probably it wouldn't be the best thing if it's just the high most highly ranked phrase or key-word because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction or something .
[36:09] Speaker_D | Yeah .
[36:09] Speaker_A | Hmm .
[36:11] Speaker_D | And it should be weighted by stuff like the hot spots and um the key-words in the search and stuff like that .
[36:16] Speaker_E | Yeah .
"[36:19] Speaker_E | Also like for this part , maybe if we go over it with named entity in the end , if I mean w if one of the people doing DIL has some named entity code to spare , and just like at least for the for sort of for finding topics , titles for for segments , just take a named entity which has a really high , what's it called , D_F_I_D_F_ , whatever . 'Cause you'd probably be quite likely if they're talking about a conference or a person , that that would be a named entity which is very highly fr um frequented in that part ."
[36:27] Speaker_A | Hmm .
[36:47] Speaker_D | Did he not say something about named entities ? So I thought he said there wasn't very many .
"[36:51] Speaker_E | Yeah , he said they're quite sparse . So that basically was don't bother basing too much of your general calculation on it . But like especially if they're sparse , probably individual named entities which describe what a what a segment is about would probably be quite good . Like if there's some name of some conference , they would could probably say that name of the conference quite often , even though he's right that they make indirect references to it . Anyway Sorry ?"
[36:52] Speaker_D | Yeah .
[37:14] Speaker_C | You s uh you said you are currently in uh implementing the idea . What exactly are you computing ?
"[37:20] Speaker_D | Yeah . It's not T_F_I_D_F_ , it's just inverse document frequency . 'Cause it's really easy to do basically . There's just like for a baseline really ."
[37:24] Speaker_C | Okay .
[37:28] Speaker_C | Okay .
[37:31] Speaker_C | Mm-hmm .
"[37:32] Speaker_A | Yeah , you're able to do that in Java , yeah ?"
"[37:34] Speaker_D | Well , I'm half-way through . It's not working yet , but it will do ."
[37:35] Speaker_A | Yeah .
[37:39] Speaker_E | So you're doing that on a on a per word level .
[37:42] Speaker_D | Um yeah . And then averaging it over the utterances .
[37:43] Speaker_E | Okay .
[37:46] Speaker_E | Okay .
[37:47] Speaker_D | But it's not like um related to the corpus at all . It's just working on an arbitrary text file at the moment .
"[37:54] Speaker_E | Okay , cool . I was just wondering where you had the corpus from at the moment ."
[37:57] Speaker_D | No .
[37:58] Speaker_A | Huh .
[38:25] Speaker_D | It would be useful to know how everyone's gonna store their things though .
[38:31] Speaker_A | Hmm .
"[38:32] Speaker_E | Yeah , that would mean understanding the NITE X_M_L_ X_M_L_ sort of format in a lot more detail . We should I think we should just have a long session in the computer room together and like now that we know a bit more what we want , take a closer look at NITE X_M_L_ ."
[38:35] Speaker_D | Yeah .
[38:44] Speaker_D | Yeah . Well I've got like a few hours free . Like after this .
"[38:48] Speaker_A | Yeah , I've had a b I've had a look at the the topic segments , how it's stored . And then yeah , th those are few per meeting , and it um well , it gives a time stamp and inside each one there's uh the actual like utterance segments ."
[38:52] Speaker_E | Mm-hmm .
[39:04] Speaker_E | Mm-hmm .
[39:05] Speaker_A | And the list of them that occurred . And they're all numbered .
[39:09] Speaker_A | Um so that's where that's stored .
"[39:15] Speaker_E | Good . Yeah , I haven't looked at this stuff much at all ."
"[39:18] Speaker_A | Yeah , so I guess um if I'm gonna be segmenting it with a L_C_ seg then that's like same format I'd want to um put it back out in so it'd be equivalent ."
[39:22] Speaker_E | Yeah .
[39:25] Speaker_E | Yeah .
"[39:40] Speaker_A | Well , like the integration . What do you mean , integration ?"
[39:42] Speaker_E | Hmm ?
"[39:43] Speaker_E | Yeah , or but also like all these elements like like the loading and , yeah , integration and and like handling the data loading and stuff ."
[39:47] Speaker_A | Hmm .
"[39:53] Speaker_E | Nah . I'm sort of like I think I'll take over the display , just because I've started with a bit and found it found it doable ."
"[40:00] Speaker_A | Yeah , yeah ."
"[40:03] Speaker_A | Yeah , definitely ."
"[40:20] Speaker_A | Hmm , yeah ."
[40:25] Speaker_E | Any volunteers ?
[40:29] Speaker_C | Mm-hmm .
[40:30] Speaker_E | It's also a complicated one .
"[40:31] Speaker_A | Yeah , it c could be difficult , yeah ."
[40:31] Speaker_D | Yeah .
[40:33] Speaker_E | Yeah .
"[40:36] Speaker_E | I know but uh b I guess we can do it like several people together , it's probably just those people have to work together a lot and very closely and just make sure that they're always f understand what the other one is doing ."
[40:47] Speaker_A | Yeah .
[40:49] Speaker_A | Well I guess the important thing is to get the crucial m modules built .
[40:54] Speaker_D | Or at least um simple versions of them .
[40:54] Speaker_A | Ye yeah .
"[41:00] Speaker_A | Yeah , and then we'll maybe have to prioritize somebody into just integrating it ."
"[41:44] Speaker_D | So maybe we should try doing something really simple , like just displaying a whole meeting ."
[41:50] Speaker_D | And like just being able to scroll through it or something like that .
[41:54] Speaker_E | Or just adapt like their like just sort of go from their system and and adapt that piece for piece and see how we could
[41:55] Speaker_D | Yeah .
[42:02] Speaker_E | how we could arran like adapt it to our
[42:06] Speaker_E | system .
[42:10] Speaker_E | Does anyone want to like just sit with me and like play for three hours with NITE X_M_L_ at some point ?
[42:17] Speaker_D | Are you free after this ?
[42:20] Speaker_E | Uh I wouldn't like to be 'cause I'd like to go to the gym . I'm theoretically free . But if there's any time t hmm ?
[42:26] Speaker_D | How about Friday then . 'Cause I'm off all Friday .
[42:30] Speaker_E | You have nothing no free time on Wednesday .
[42:38] Speaker_E | Hmm .
[42:42] Speaker_E | Hmm ?
"[42:45] Speaker_E | Anytime Wednesday afternoon I'd be cool , I think ."
[42:46] Speaker_D | Okay . So you ha yeah .
"[42:50] Speaker_D | Where about , just in Appleton Tower ?"
"[42:53] Speaker_E | Yo , Forrest Hill , whatever one's easier to discuss stuff , I don't know ."
[42:56] Speaker_D | Uh I'll be in um the Appleton Tower anyway .
[42:58] Speaker_E | I'm not biased .
[43:00] Speaker_E | Okay . What time do you wanna do ?
"[43:10] Speaker_E | Okay , so I'll just meet you in in eighteen a in the afternoon ."
[43:12] Speaker_D | Yeah .
"[43:28] Speaker_E | I guess at the moment nobody critically depends on like the NITE X_M_L_ stuff working right now , right ? Like at the moment you can all do your stuff and I can do my L_S_A_ stuff . And I can even do the display to a vast degree without actually having their supplying framework working . So it's not that crucial ."
[43:37] Speaker_A | Mm-hmm .
"[43:47] Speaker_A | Yeah , I think so ."
"[43:47] Speaker_C | Yeah , I w I w I would need the raw text pretty soon because I have to find out um how I have to put the segments into bins . And then yeah ."
"[43:59] Speaker_E | Yeah , actually I need the raw text as well . Yeah , but I was I was I was more thinking of the sort of the the whole browser framework as a running programme now . Yeah , I think we all need the raw text in different in different flavours , don't we ?"
[44:01] Speaker_A | Uh yeah .
"[44:04] Speaker_C | No , that's not necessary ."
"[44:09] Speaker_A | Hmm . Yeah , yeah . Jasmine , I thought you just said that you'd uh looked at extracting the text ."
[44:09] Speaker_D | Why w
"[44:23] Speaker_A | Yeah . So you you said you did it in Python , yeah ?"
"[44:28] Speaker_A | Yeah , did you use uh b the X_L_ uh X_M_L_ parser in Python ? Right . Yeah , sounds pretty good . So um 'cause , yeah , I was having a look in it a look at it as well and I noticed the um the speakers are all in that separate file ? So did did you have to combine them all and and then re-order them ?"
[44:31] Speaker_C | Yeah . Yeah .
[44:38] Speaker_C | Mm-hmm .
"[44:46] Speaker_C | Yeah , b I uh w that's what I was uh thought . That you just combine them and then order the time stamps accordingly ."
[44:49] Speaker_A | Yeah .
"[44:51] Speaker_A | Ye yeah , c"
"[44:53] Speaker_A | Right . Yeah , so that's approach um well , I was going to do . So yeah , we may as well collaborate ."
[44:59] Speaker_C | Okay . Um what I found out was that there are quite a lot of things without without s time stamps in the beginning .
[45:08] Speaker_A | In the word files ?
"[45:09] Speaker_C | Yeah , and uh X_M_L_ files . Yeah , that's just an I_D_ or something . I don't know . Just numbers ."
"[45:14] Speaker_B | Yeah , everything that's a word has a sti time stamp ."
"[45:18] Speaker_C | Yes , but what are the other things that's uh some kind of number ? F maybe the file number or something that is in the beginning . What is that ?"
[45:28] Speaker_A | I'm not sure I what you mean .
[45:28] Speaker_C | Do you know ?
[45:30] Speaker_C | Um I think there are quite a lot of numbers in the beginning where n there is no time stamp for the numbers .
[45:45] Speaker_E | But number within the X_M_L_ context .
"[45:47] Speaker_C | Yeah , there i are numbers in the um the W_ tag , but there are no time stamps ."
"[45:53] Speaker_E | Are they spoken numbers ? Like do they look like they're utterances numbers ? There's the number task , isn't there . That's part of the whole thing . Hmm ?"
[45:56] Speaker_C | Yeah .
"[45:59] Speaker_B | That's at the end . That's at the end , I think , her time ."
[46:02] Speaker_E | Okay .
"[46:03] Speaker_C | Yeah , in the beginning as well sometimes , I think . At least I saw some ."
[46:05] Speaker_A | Oh right .
"[46:06] Speaker_B | Yeah , maybe ."
[46:09] Speaker_B | Didn't have a look at our meetings .
[46:09] Speaker_C | Yeah .
[46:15] Speaker_C | Yeah .
[46:16] Speaker_A | Hmm .
"[46:29] Speaker_B | And I think it even has uh its own annotation , like digits or something . So that should be really easy to cut out ."
[46:34] Speaker_E | Okay . Uh I'm just thinking like it pro it pro probably like the L_S_A_ would perform quite well on it . It would probably find another number task quite easily seeing that it's a constrained vocabulary with a high co-occurrence of the same nine words . So that wou ten word . Hmm ?
[46:48] Speaker_C | But what it is it actually that numbers ?
"[46:50] Speaker_B | Ah it's just to test the system , I think ."
"[46:53] Speaker_C | Okay , so but there are no time stamps annotated to that . It's it's quite strange ."
"[46:56] Speaker_E | I think it's also something that they they said the numbers in order , right ?"
"[47:03] Speaker_E | Yeah , I think it's it the it sounded like they wanted to check out how well they were doing with overlapping and stuff , because basically it's like they're reading them at different speeds , but you know in which order they are said . Anyway . ICSI has some reasons for doing it . They must have been pissed off saying like numbers at the end of every meeting ."
[47:18] Speaker_A | Hmm .
[47:24] Speaker_C | And also um there are different um combinations of letters . B_R_E_ and something like that . Is it everything ordered are the time stamps global or uh are they local at any point ?
[47:39] Speaker_A | Mm I thought they were local to th a particular meeting .
"[47:42] Speaker_E | Um Dave , if you would or actually for well , if you're doing I_D_F_s or you whatever you call your your frequencies , I always mix up the name , uh you need some dictionary for that at some point though , like you need to have some representation of a word as not not that specific occurrence of that word token , but of of of a given word form . Because you're making counts for word forms , right ? Yeah , so we should work together on that , because I need a dictionary as well ."
[47:42] Speaker_C | Okay .
[48:05] Speaker_D | Yeah . I'm just building a dictionary .
"[48:10] Speaker_D | Oh , mine's just gonna use the um hash map one in um Java . 'Cause I'm only gonna do it on small documents . It's just like bef until the information density is up and running . Just something to get give me something to work with ."
[48:16] Speaker_E | Okay .
[48:20] Speaker_E | 'Kay .
[48:24] Speaker_E | Okay . Didn't you say that the o the ord
"[48:25] Speaker_D | So it's only gonna use quite small documents , you see , to start with ."
"[48:29] Speaker_E | Yeah , but for I'm just wondering for the whole thing . Does somebody wo who was it of you two who said that um there's some programme which spits out a dictionary probably with frequencies ?"
"[48:55] Speaker_C | Um no , I have to bin it up and so I will only have counts for each each bin or something ."
[49:03] Speaker_D | Why does it need to be classified into like different segments ?
[49:07] Speaker_C | It's because um Rainbow is a text classification system . And I think it's not possible to have just one class . That's the problem .
[49:17] Speaker_D | Can we just fill a second class with junk that we don't care about ?
"[49:25] Speaker_C | Yeah sure , you sure , we could do that , but I don't that makes sense ."
"[49:29] Speaker_D | 'Cause if what we're looking for is the um frequency statistics , I don't see how that would be changed by the classification ."
[49:48] Speaker_D | Well there maybe another tool available ?
"[49:51] Speaker_C | Yeah , it's quite easy to just count and s or sort them by um frequency ."
[49:54] Speaker_D | Yeah .
[49:56] Speaker_E | W using which tool are you talking about ?
[49:58] Speaker_C | Just using a Perl script .
[50:00] Speaker_E | Be careful with that . Like my experience with the British National Corpus was that there's far more word types than you ever think because anything that's sort of unusual generally is a new word type . Like any typo or any strange thing where they put two words together . And also any number as a word type of its own . So you can easily end up with hundred thousands of words when you didn't expect them . So generally dictionaries can grow bigger then you think they do .
[50:05] Speaker_C | Is it too big ?
[50:10] Speaker_C | Yeah .
[50:19] Speaker_C | Hmm .
[50:26] Speaker_C | I don't know how you how many terms you can handle in Perl .
[50:37] Speaker_C | Mm yeah .
[50:45] Speaker_D | Um I can't remember who's got it . Might be WordNet . But one of these big corpuses has a list of stop words that you can download and they're just basically lists of really uninteresting boring words that we could filter out before we do that .
"[51:04] Speaker_D | It's like that's one the papers I read , that's um one things they did right at the beginning is they've got this big s stop-list and they just ignore all of those throughout the experiment ."
"[51:13] Speaker_E | What I did , for my project I just ignored the hundred most frequent words , because they actually end up all being articles and and everything and stuff ."
[51:26] Speaker_E | So we need like several of us need a dictionary . Am I the only one who needs it with frequencies ?
"[51:30] Speaker_D | Yeah , I it would be useful for me as well ."
[51:37] Speaker_D | It uh I think that'd be useful for me as well . Yeah .
"[51:39] Speaker_E | Frequencies . Yeah . Well I guess as soon as we have the raw text , we can probably just start with the Java hash map and like just hash map over it and see how far we get . I mean we can probably on a machine with a few hundred megabyte RAM you can go quite far . You can write it on beefy . So even if it goes wrong and even if it has a million words be"
[51:45] Speaker_D | Yeah .
[51:55] Speaker_D | Well all you really wanna do is look into getting some sub-set of the ICSI corpus off the DICE machines . 'Cause I hate working on DICE . It's awful .
[52:05] Speaker_D | Like so I can use my home machine .
"[52:29] Speaker_D | Yeah . The right-hand corner , far right ."
"[52:31] Speaker_E | Yeah , if you if you enter the big room , in the right-hand corner , I think . Um the thing is like you can only burn from the local file-system . So if it's from s well actually I think if it's mounted , you can directly burn from there , but the problem is I have my data on beefy and so I have to get it into the local temp directory and burn it from there . But you can burn it from there ."
[52:34] Speaker_D | Yeah .
[52:34] Speaker_B | Mm-hmm .
[52:50] Speaker_D | How big is it without um
[52:54] Speaker_E | Uh we looked that up and I for we looked that up and I forgot .
[52:54] Speaker_D | the WAV files and stuff ?
[52:58] Speaker_D | 'Cause I could just say at um going over S_C_P_ one night and just leave it going all night if I had to .
"[53:05] Speaker_E | Yeah yeah . No , you you we should be able to get it at I don't think it was I don't think it was a gigabyte ."
"[53:12] Speaker_D | It's yeah , I mean the wave data are obviously not gonna get off there completely ."
[53:13] Speaker_E | Hmm .
"[53:17] Speaker_E | See I would off I would offer you to to get it on this one , and then um like copy it . But you know what I figured out , I'm quicker down-loading over broad-band into my computer than using this hard disk . There's something strange about the way how they access the hard disk , how they mount it , which is unfortunate ."
[53:25] Speaker_D | Really ? Oh right ?
"[53:34] Speaker_D | I'll see if I can S_C_P_ it , I suppose ."
[53:38] Speaker_E | Hmm . What operating system do you have ?
[53:43] Speaker_E | Okay . Wh what connection do you have at home ?
[53:45] Speaker_D | Broad-band .
"[53:46] Speaker_E | Yeah . So if anyone of us gets it , we can then just use an ext hmm ? Yeah , burn it to C_D_ or , yeah , put it on on hard disk , whatever ."
[53:49] Speaker_D | Put it on to C_D_ . I can if I get down I can put to C_D_ .
[53:54] Speaker_D | Yeah .
[54:07] Speaker_D | I'm not sure if there's enough space . Is how much do we get ?
"[54:09] Speaker_E | The temp the temps usually have for gigabyte three or two . The temps , yeah . I do like I mean there's not guarantee that anything stays there , but overnight it'll stay . And I think the temps usually have ."
[54:13] Speaker_D | Really ? Okay .
"[54:26] Speaker_E | Ah yeah , but that would have to be the temp directory off the machine you can S_S_H_ into directory of S_S_H_ ."
"[54:32] Speaker_D | Yeah , but I can do it from that session , can't I ? You can compress it from a remote session and S_C_P_ it from the same session ?"
"[54:49] Speaker_E | They'd probably they'd like you more if you S_S_H_ uh into another computer , compress it there and then sort of copy it into the into the gateway machine ."
[55:00] Speaker_D | Do you think ?
"[55:01] Speaker_E | They have um if you S_S_ hey , you know , if you if you S_S_H_ and they have this big warning about doing nothing at all in the gateway machine ."
"[55:05] Speaker_D | Yeah . Oh no no , I was thinking of SSHing just into some machine and then just SCPing it from there ."
[55:10] Speaker_E | Yeah .
[55:15] Speaker_E | To your home machine .
[55:18] Speaker_E | I haven't I haven't figured out how to tunnel through the gateway into another machine yet . It's not it's not easy definitely . That's why I end up sort of copying stuff into the temp directory at the gateway machine . Sorry if this is boring everybody else . This is just details and how to get stuff home from what we can probably just look at that together when we're meeting .
[55:21] Speaker_D | Can you not do that ?
"[55:28] Speaker_D | Mm , I see ."
[55:34] Speaker_B | Uh th yeah .
[55:36] Speaker_D | Yeah .
[56:01] Speaker_E | I'm sorry .
[56:07] Speaker_E | Mm-hmm .
[56:24] Speaker_E | Well yeah .
[56:43] Speaker_B | You know ?
"[56:46] Speaker_B | Yeah , but I'd uh I would like to look at the frequency of words in my um in the regions of text I found out to be interesting . So I wouldn't need it . It it would have to be re-calculated only for my segments ."
"[57:02] Speaker_E | Yeah , you'd have to count it yourself , yeah ."
"[57:05] Speaker_D | But th first , uh how big are the chunks ?"
[57:08] Speaker_B | Huh ?
[57:09] Speaker_D | How big are the chunks you're looking at ?
"[57:10] Speaker_B | Uh uh mm . I think it would be , you know , l as as big at as the hot-spot annotation things . That's quite small , yeah , that's some utterances ."
"[57:22] Speaker_D | So quite small then . So you could just um you could use just the same thing we used to build the big dictionary . You just do that on-line 'cause that won't take long to build a little dictionary that big , will it . I mean just use the same tool that we use . Yeah ."
[57:26] Speaker_A | Hmm .
"[57:39] Speaker_B | Yes . Yeah , yeah . So I would probably just concatenate all my um text chunks and then let's say m I will run over it ."
[57:44] Speaker_D | Yeah .
"[57:49] Speaker_E | Oh , you don't wanna have different counts for each chunk , but just like sort of for for something from old chunks . Oh yeah , no , that's yeah , so once I write an ar like w if I write like an algorithm which does a hash um table dictionary with frequency from a raw text , then the raw text can be anything . So how far are we g uh how f how far are you getting raw text out of it do you think ?"
[57:55] Speaker_B | Yes .
"[58:20] Speaker_D | It doesn't need ordered , no ."
"[58:22] Speaker_C | No , it isn't ."
[58:36] Speaker_D | Um well that's the t are you using T_F_I_D_F_ for the information density ?
"[58:43] Speaker_C | Um it's in what is implemented in Rainbow is information gain , and I'm not quite sure how they calculate that ."
"[58:48] Speaker_D | Alright , okay ."
"[58:52] Speaker_D | Like 'cause frequency would be useful , I think . But um depending on the context , the size , and what we consider a document in the sense of calculating T_F_I_D_F_ is gonna change ."
"[58:57] Speaker_E | Yeah , I I need frequency as well ."
[58:57] Speaker_C | Yeah .
[59:10] Speaker_D | Which might need thinking about .
"[59:12] Speaker_E | Well I think we might have a lot in common what we calculate because I for my latent semantic analysis need like counts of words within a document , uh within a a segment actually , within a topic segment ."
[59:23] Speaker_C | Uh that's what Rainbow does . I think you j can just get probabilities for a certain words for each document .
[59:32] Speaker_E | Can I convert these probabilities back into frequencies ?
[59:35] Speaker_C | Um we would have to look at that .
[59:38] Speaker_E | Okay .
[59:45] Speaker_C | Mm-hmm .
[59:47] Speaker_C | Oh .
"[59:56] Speaker_E | Yeah , so Dave , you said you need the frequency counts actually for per document , would you say , not for the whole thing ?"
"[59:59] Speaker_D | I think it would be useful , yeah ."
[00:02] Speaker_D | Well you need the raw frequency as well . But um
[00:09] Speaker_D | you also need how many times things occur within each document .
"[00:17] Speaker_D | And um what we consider a document's gonna depend on our context , I think . 'Cause if we're looking at the whole lot of meetings , we'll consider each meeting a document in sort of terms of this algorithm . And if we're viewing like say just a small topic segment you might look at even each utterance as a small document ."
"[00:39] Speaker_E | It more and more appears to me that if we if we scrap the notion of the meeting as an individual thing and sort of ju see meetings as as topic segments and have sort of like hierarchical topic segmentation instead , then it's b like a more coherent framework ."
"[01:06] Speaker_D | Actually maybe it doesn't actually matter . Maybe if you just do it once at the highest level , it it will be fine . But I was just thinking it might be difficult to calculate the T_F_I_D_F_ off-line for all the different levels we might want . 'Cause if we're gonna allow disjoint segments for example , then how are we gonna know what's gonna be in context at any given time ? But I suppose if you just did it globally , treating a meeting as a document , it'd probably still be work out fine , because you'd only be comparing to ones within the context ."
"[01:38] Speaker_E | Wait , are we are we using this um for the for the for the do for the weighting in the end now , this this measure you're calculating ?"
"[01:49] Speaker_D | Uh I don't know , I thought were you gonna use that in the end ?"
[01:55] Speaker_D | The information density .
"[02:09] Speaker_D | Oh sorry , that's what I mean . Like um yeah , for each word or whatever , but across the whole lot is what I mean by highest level . Like across the whole corpus ."
"[02:19] Speaker_E | Yeah , but w it don't you have to like go sort of like for in a document versus the whole thing ? Isn't that how it works that you c look look at r"
"[02:26] Speaker_D | Yeah , but you'd probably look at each meeting as a document ."
[02:29] Speaker_E | I don't think that's a good idea because isn't it like that we expect th there to change over i b with the different topic segments more ? That they talk about something different in each different topic segment .
[02:46] Speaker_D | Mm possibly .
"[02:51] Speaker_E | 'Cause that's what relative term frequency is about , that like in some context they're talking more about a certain word than in general . So that would more be the the topic segments then ."
"[03:03] Speaker_C | Yeah , that's what I thought as well , that you that probably the the topic segment level is the most um informative for the words ."
[03:03] Speaker_E | I don't know .
[03:05] Speaker_E | Yeah .
[03:12] Speaker_E | Yeah . Yeah .
[03:14] Speaker_D | Are they big enough to get anything meaningful out of ?
"[03:16] Speaker_C | Yeah , that's the problem . I don't know ."
"[03:34] Speaker_D | Well yeah , that is not it's not an issue . You just concatenate an X_M_L_ file together . but we still want to have like a notion of meetings for the user ."
"[03:43] Speaker_B | Yes , definitely ."
"[03:46] Speaker_E | But on algorithmic level , whether we actually whether there's some way to just represent meetings as as topics ."
"[03:50] Speaker_D | Yeah , sure . Yeah , you just like whatever you want to look at , you just jam together into an X_M_L_ file and that's your meeting , even though bits of it may come from all over the place or whatever . I mean I don't see why that's really a big problem ."
[04:02] Speaker_E | Hmm .
[04:08] Speaker_E | That's not really what I meant . But I think I have to think more about what I meant .
[04:16] Speaker_D | So basically what you're saying is you can take an arbitrary amount of data and process it with the same algorithm . It doesn't matter conceptually what that data is . It could be a meeting . it could be two utterances . it could be a meeting plus half a meeting from somewhere else .
[04:29] Speaker_E | Yeah .
"[05:04] Speaker_D | I don't think it's very difficult though . I mean what you do is you just build an X_M_L_ file , and if you want it to get down to the utterances , you'd go to the leaves . And then if you wanted the next level up , you'd go to the parents of those and like just go from like the leaves inwards towards the branch to build up things like um you know , when you click on a segment , it's gonna have like words or whatever that are important ."
[05:34] Speaker_E | Hmm .
[05:37] Speaker_E | Mm I'm not really sure what I want .
"[05:39] Speaker_D | As long as like the algorithms are designed um with it in mind , I don't think it's a very big problem ."
"[05:49] Speaker_D | Well like say you had um like say for a meeting , right , you've got like uh say a hierarchy that looks quite big , like this ."
[06:01] Speaker_D | And like the utterances come off of here maybe .
[06:04] Speaker_E | Mm-hmm .
"[06:06] Speaker_D | Then when whatever your algorithm is doing , as long as when you're working with utterances , you go for all the leaves , like then if you need something next up , so like a topic segment , you'd go to here . But if you were looking at say this one , so only went like this ."
[06:08] Speaker_E | Mm-hmm .
"[06:25] Speaker_D | Right , so you it's same , you'd start with the leaves , and you go oh , I want a topic segment . So I go one layer up ."
[06:31] Speaker_E | Mm-hmm .
"[06:32] Speaker_D | See , and then if you're working with just a topic segment in there , it's the only thing you have to worry about . And like each time you want a higher level , you just need to go up the tree . And as long as your algorithm respects that , then we can just"
[06:48] Speaker_D | process any arbitrary X_M_L_
[06:51] Speaker_D | file with whatever hierarchical structure we want .
"[06:55] Speaker_E | So that would be the series as a whole . That would be sort of m meetings , yeah ."
"[06:59] Speaker_D | A meeting , say , and that would be a topic segment ."
"[07:03] Speaker_E | Yeah . I'm a I'm a I'm a bit brain-damaged at the moment , but I think I'll just sit together with you again and and go through it again ."
[07:15] Speaker_E | Hmm .
"[07:27] Speaker_D | Well no , it doesn't have to be ."
"[07:31] Speaker_D | But I mean it could be as many nodes as you want . Like this one could be deeper maybe ,"
"[07:37] Speaker_D | say . So then you'd start with all your utterances here , and when you go up to get topic segments , you go to here here here here here here here ."
[07:47] Speaker_D | That might be a bit confusing though 'cause you have things on different levels .
"[07:52] Speaker_E | Yeah , I'm also not sure how we can go from from bottom-up . I have always thought it's like more that oh , whatever , I'm a can't think of it at the moment ."
[08:06] Speaker_E | Probably this is all too complicated worrying about that at that moment anyway .
[08:19] Speaker_A | Mm is there anything else we should discuss ?
"[08:22] Speaker_E | Now have have we have we decided anything , are we doing anything ? S Wednesday we are meeting and looking at their at their implementation in some more detail to actually understand what's going on ."
[08:26] Speaker_D | Well Wednesday . Yeah .
[08:32] Speaker_D | Yeah .
[08:34] Speaker_D | So we'll see if we can get like a mini-browser just displays two things synched together of some kind . Yeah . Yeah .
"[08:40] Speaker_E | We had two things from their stuff just to make sure that we are like understand it , we understand it enough to to m modify it ."
"[08:47] Speaker_A | Yeah , should we not have like a group directory or something where we can put all our code in and that kinda thing ?"
[08:53] Speaker_D | It'd be useful . I don't know who you see about that though .
[08:56] Speaker_A | Hmm .
[08:58] Speaker_E | Yep . How would we do that ? By just making like it w read write for everyone .
[09:09] Speaker_C | Mm-hmm .
[09:09] Speaker_D | I d have no idea .
[09:13] Speaker_D | I've probably got a reasonable amount because um everything on my DICE account can actually be deleted 'cause I store it all at home as well .
[09:22] Speaker_A | Hmm .
[09:23] Speaker_E | Well we alternatively we can probably just make another directory on the beefy scratch space . I mean that's where I'm having gigabytes and gigabytes of stuff at the moment .
[09:34] Speaker_E | No . No .
"[09:36] Speaker_A | Yeah , we can ask Steve if um we can get space ."
[09:40] Speaker_E | Yeah .
[09:43] Speaker_D | Maybe you should send a support form .
"[09:45] Speaker_A | Yeah , uh we could do that ."
[09:46] Speaker_E | But I think if he sends to the I think if he sends to the port he'd probably be in a better position . Yeah .
[09:46] Speaker_D | Just say we want some web space .
"[09:53] Speaker_A | Yeah , I'm sure he had to deal with that last year ."
[09:55] Speaker_D | Yeah . 'Cause that'd be really useful is if we had a big directory . Especially for transferring stuff .
[10:01] Speaker_E | Hmm .
"[10:06] Speaker_D | Having said that , are we allowed to take a copy of the ICSI corpus ? Something we should probably ask before we do it ."
"[10:12] Speaker_E | I think he said yes to that . I think uh that was like in when we were still in the seminar room , I asked that once or like ask is it possible to get it off and nobody said like people were discussing about the technical practicalities , but nobody said anything about al being allowed to or not allowed to . I mean , we have access to it here and I guess it probably means that we we can't give it to anybody else . But"
[10:16] Speaker_D | Okay .
[10:33] Speaker_D | Okay .
"[10:36] Speaker_E | but if they give us access to it here o sitting on a DICE machine , then there shouldn't be a reason why we shouldn't be able to use it on our laptop . I personally don't have too many friends who would be too keen on getting it anyway ."
[10:47] Speaker_E | I have that really excited pirate copied thing . It annotated meeting data .
[10:52] Speaker_C | So shall we sit together tomorrow then as well ? Uh Okay .
[10:54] Speaker_A | Yeah .
"[10:56] Speaker_B | Um Jasmine , uh um what is um the text you're extracting uh looking like then at the end ?"
[11:08] Speaker_B | Because um I I think it's actually very similar to what I did for my um speaker um uh extraction and I think I would ch perhaps have to change two lines of codes to get you um for each meeting a file that says fr from um this millisecond to this millisecond there was this sequence of words .
[11:12] Speaker_C | Mm-hmm .
[11:34] Speaker_B | And so on .
[11:52] Speaker_C | Okay .
[11:55] Speaker_C | Mm-hmm .
[11:57] Speaker_C | Print out .
[12:09] Speaker_B | Should be very
[12:11] Speaker_B | straight-forward .
[12:22] Speaker_C | Okay .
[12:31] Speaker_E | Huh .
[12:31] Speaker_C | So have we already extracted from all the files ?
[12:36] Speaker_C | Yeah .
[12:41] Speaker_B | Yes . I just ordered .
[12:41] Speaker_C | Mm-hmm .
"[12:41] Speaker_E | Wait , wait , wait . Um sorry . Yeah , sorry ."
[12:45] Speaker_B | Uh I ordered according to the um starting times of the utterances .
[12:49] Speaker_C | Hmm .
"[12:51] Speaker_E | What I just realised , we should really t keep different serieses completely separate for virtually all purposes . Just let's be careful about that , because"
[13:01] Speaker_B | What do you mean by diffe
"[13:02] Speaker_E | like the the ICSI corpus isn't isn't one meeting series , it's several meeting series with different people meeting for completely different things ."
[13:07] Speaker_A | Hmm .
"[13:12] Speaker_B | Yeah , I mean t I I have one what I give you would be one file for each meeting ."
[13:20] Speaker_E | For each meeting .
"[13:21] Speaker_B | Yeah , not for each meeting series . I didn't do that yet ."
[13:22] Speaker_E | Alright .
"[13:23] Speaker_E | Okay , but like let's just be careful that whatever we sort of we merge together , that like the highest level of merging , it's not the whole ICSI corpus but individual series ."
[13:31] Speaker_C | Hmm .
"[13:57] Speaker_E | Oh yeah , let's take that ."
"[14:04] Speaker_B | Yes . Um the you you the data is of the form you have um three identification letter . So B_E_D_ or B_B_D_ or something , and that's always the same group . And then after that there's um a number like O_O_ one , O_O_ two . So , it's a"
[14:11] Speaker_E | Okay .
[14:13] Speaker_E | Okay .
[14:15] Speaker_E | Okay .
"[14:30] Speaker_B | Yeah , but that's that's really quite easy to see because they're named ."
[14:30] Speaker_A | Hmm .
"[14:52] Speaker_B | Yes . But I I mean as um the start uh start times um start for each meeting at zero , you could just probably just um add the um final second time to the next meeting and so on and just put it all together . But then we would have to change um the information about who on which channel it was set , um to by which person it was set . And that is actually stored in another X_M_L_ document ."
[14:57] Speaker_E | Mm-hmm .
[15:12] Speaker_E | Yeah .
[15:26] Speaker_A | Hmm .
"[15:26] Speaker_E | 'Kay . Um so is is anybody creating an uh a real raw text thing at the moment , like which is just the words ?"
"[15:34] Speaker_A | Yeah , that's what I'm gonna need ."
"[15:37] Speaker_E | Yeah , tha 'cause that's what I'm gonna need as well ."
[15:43] Speaker_A | Yes .
"[15:44] Speaker_A | Yeah , it's just mo changing it a bit ."
[15:45] Speaker_C | Okay .
"[15:50] Speaker_B | No , it's for every single word ."
[15:53] Speaker_D | We can just change the code .
"[15:53] Speaker_B | Or for every single utterance . Yeah , that depends on what you want ."
[15:55] Speaker_A | Yeah .
[15:56] Speaker_E | So what do you mean by just not print out that ?
[16:03] Speaker_E | Okay .
"[16:05] Speaker_E | If you're into it , can you make a text file which just like makes just the words ? 'Kay . Do you want it straight flowing , 'cause I would need something that marks the end of uh of uh is is yours segmented by topics then that like is there any information that you have to the topic , to the automated topic topic segmentation ? Oh then I need something different later anyway . Okay , but for now , if you c"
"[16:22] Speaker_B | No , I didn't do a sea no ."
"[16:27] Speaker_A | No , but uh that's what M_L_C_ seg does . It it marks the end of each segment ."
[16:34] Speaker_A | Yeah .
[16:44] Speaker_A | Yeah .
[16:53] Speaker_B | For the series .
"[17:02] Speaker_E | But if you can put it in one single mega-file , that would be quite useful for me ."
[17:06] Speaker_B | So uh only words um per meeting series .
[17:06] Speaker_A | Oh .
[17:16] Speaker_A | Yeah .
"[17:18] Speaker_A | Yeah , for me it's better if they're by meeting ."
[17:23] Speaker_B | Uh-huh .
[17:27] Speaker_B | Yes .
"[17:30] Speaker_B | Yeah , they will just I will just take I would uh take over the names they have anyway ."
"[17:36] Speaker_E | Yeah . Is is it something that's easily enu like to enumerate over ? Is it some just some ordered pattern ? Okay , cool ."
"[17:40] Speaker_B | Yeah , yeah ."
"[17:47] Speaker_E | Okay , cool . Yeah ."
[17:57] Speaker_E | In the right order .
[18:05] Speaker_B | Um ord base dot times .
"[18:14] Speaker_C | Yeah , that doesn't matter too much , I think ."
[18:16] Speaker_B | Just after th mm-hmm . 'Kay .
[18:20] Speaker_B | Ordered . Only words .
[18:27] Speaker_E | When do you think you'll have um like a primitive segmentation by some ready-made topic segmentation by some ready-made tool ready ?
[18:35] Speaker_A | Then that'll be really easy to do once they've got the raw text . It's just a case of running the script .
[18:39] Speaker_E | Okay .
"[18:41] Speaker_E | Okay , cool . 'Cause I'll need that then when it's done ."
"[18:44] Speaker_A | Yeah , I mean hopefully this week ."
[18:46] Speaker_E | Okay .
"[18:47] Speaker_B | Um and I think um for all the corpus , it's just from I know from other times , it's um nine megami byte to have I mean should be should be similar to have the words . Should be ."
[18:54] Speaker_E | Mm-hmm .
[18:57] Speaker_D | Is that it ? That's quite good .
[19:02] Speaker_B | Na um all the words together um for all the meetings .
[19:06] Speaker_A | Alright .
[19:07] Speaker_E | That sounds quite reasonable . That's nine nine characters over okay .
"[19:09] Speaker_B | That's what I'm guessing that's , you know , um what I because nine mega-byte is what I got for when I said for every um utterance , this is goes from there to there and"
[19:22] Speaker_B | takes takes seconds .
[19:29] Speaker_E | Yes .
[19:33] Speaker_E | Okay .
"[19:35] Speaker_E | Yeah . Yeah , I guess we can probably process the data for all different series and then check which series is the best for the presentation . It sounds quite reasonable , nine megabyte . I mean if you think if it's r roughly a million words and nine characters per word sounds realisti"
[19:41] Speaker_D | Yeah .
[19:55] Speaker_E | Yeah .
"[19:58] Speaker_E | Yes , I'm gonna build a dictionary then from that . Like just a list of the words that maybe a list of the words with the frequencies or a list of the words sorted alphabetically or numerically . What what does anyone want ? Does this there any wishes for dictionaries ?"
"[20:16] Speaker_D | I could just use it with the frequency , I think , until the information density thing's finished . That would be really useful ."
[20:24] Speaker_B | Mm-hmm . Mm . So so um I will probably send um just one file of the first meeting um to all those who need it so that you can have a look whether that's what you want .
[20:25] Speaker_C | Hmm .
[20:26] Speaker_E | So I'll create a dictionary .
"[20:38] Speaker_E | Add add the structure , yeah . And then the actual file we can probably like copy from your home directory or something like it ."
[20:39] Speaker_C | Mm-hmm .
"[20:44] Speaker_B | Yeah , I mean if it's just for one meeting , it's really not too big ."
"[20:47] Speaker_E | Yeah yeah , but I'm sa I'm saying for the whole thing in the end . Then like the big thing we probably shouldn't do by email ."
[20:49] Speaker_B | Yeah .
[20:55] Speaker_E | Yeah .
[20:56] Speaker_C | How long would it take to make the frequency counts with a Java hash table ?
"[21:03] Speaker_E | Oh , from the time I get the file I can do that in an afternoon , the next sort of the next morning . Oh , you mean how long processing time it takes ."
[21:08] Speaker_C | Yeah .
"[21:11] Speaker_C | No , how long you would have to program something ."
"[21:13] Speaker_E | Ah , it's a it's a bog standard algorithm . I've I've sort of I've written it for for DIL just in half an hour or something similar . It's just you put them in a hash table and and say well if it exists already in the hash table then you increase the count by one and I'll probably implement some filter for filtering out numbers or something ."
[21:19] Speaker_C | Okay .
[21:26] Speaker_C | Mm .
"[21:30] Speaker_C | Because it's quite easy in Perl as well , it's just a line of code for counting all the words and yeah , it's it's by hashes ."
[21:37] Speaker_E | Really ? How do you do that ?
[21:41] Speaker_C | Yeah .
[21:55] Speaker_C | 'Kay .
"[22:01] Speaker_D | If you're doing it in Java , could you um serialize the output as well as writing it to a file ? If you're doing it in Java , could you serialize the um dictionary , yeah , as well as writing it to a file ?"
[22:07] Speaker_E | Sorry ?
[22:11] Speaker_E | The hash table ?
[22:14] Speaker_E | Uh I've never serialized anything .
[22:16] Speaker_D | It's really easy .
[22:18] Speaker_E | Wouldn't that be absolutely massive though ?
[22:21] Speaker_D | I don't see why it'd be any more massive than the file .
[22:24] Speaker_E | And then seriali and then write the serialization to a file . So you want like a se like a file which is the serialization of a hash table .
[22:27] Speaker_D | Yeah .
[22:31] Speaker_D | It just saves you parsing the um
[22:34] Speaker_E | Okay .
[22:35] Speaker_D | file representation of it . And now 'cause I would be using it in Java anyway . So I'd just be building the data structure again .
"[22:41] Speaker_E | Yeah . I I'll I'll check if I understand how it works . I mean otherwise I can give you the code for loading a dictionary . Give you my my it's just it's it's sort of it's a line break separated file , you know ."
"[22:51] Speaker_D | Yeah , but it seems like a bit silly to be parsing it over and over again kinda thing ."
[22:57] Speaker_E | Yeah .
"[23:02] Speaker_E | Yeah , I'll see if I understand how to serialize . There's a there's a serialise command so that gives me one mega mother of a s"
[23:07] Speaker_D | I would've thought that um I think all the collections and things implement serializable already .
[23:17] Speaker_D | I think they might do .
"[23:20] Speaker_E | Yes , is that pretty much"
[23:24] Speaker_E | pretty much it ?
[23:32] Speaker_D | Tonight I'll try and um I'll either work some more on uh the T_F_I_D_F_ summarizer or do the audio thing .
[23:41] Speaker_E | Hmm .
[23:45] Speaker_E | I'll build a dictionary as soon as I get the text .
[23:55] Speaker_E | When do we have to meet again then with this ?
[23:59] Speaker_A | Don't know . Suppose we're just getting on with all our
[24:02] Speaker_D | Yeah .
[24:04] Speaker_E | How are we gonna do a demonstrator next week ? My God .
[24:07] Speaker_D | Do we have to demonstrate something next week ?
[24:07] Speaker_A | I know . Wa
[24:09] Speaker_B | What do we have to demonstrate ?
"[24:10] Speaker_E | No no , not demonstrate , but like didn't you say that uh didn't we sort of agree that it would be useful to have a demonstrator of it , like some primitive thing working next week ."
"[24:19] Speaker_A | Yeah . Yeah , he suggested that we could have an uh initial prototype ."
"[24:26] Speaker_A | I know , I'd b I'd be surprised if we can get anything working by next week ."
[24:27] Speaker_D | Yeah .
[24:41] Speaker_A | Alright .
"[24:52] Speaker_D | Yeah , I know ."
[24:58] Speaker_D | I think it's 'cause we had to specify it ourselves that it's not as um like focus the specification of most um work we have to do .
"[25:06] Speaker_E | Yeah , but it at the moment but at the moment it's also an implementational level . Like with the data structures , I'm just like over these vague ideas of some trees , I'm f"
[25:13] Speaker_D | Yeah .
[25:15] Speaker_D | Once we start doing it it will all become more or less obvious I think anyway .
