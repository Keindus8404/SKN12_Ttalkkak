[00:00] me013 | Am I on ? I guess so .
[00:03] me013 | Radio two .
[00:05] me013 | Hmm .
[00:06] me013 | Radio two .
[00:08] me018 | Video killed the radio star .
[00:11] me013 | Wow .
[00:15] me006 | Hi ?
"[00:17] me018 | Blow into it , it works really well ."
[00:18] me026 | Channel B .
[00:19] me013 | People say the strangest things when their microphones are on .
[00:20] fn002 | Channel four .
[00:22] fn002 | Test .
[00:23] fn002 | OK .
[00:27] mn007 | Radio four .
[00:39] fn002 | Today 's
[00:39] me013 | So everybody everybody 's on ? Yeah .
[00:45] me013 | with Hynek which I unfortunately had to miss .
[00:49] me013 | Um
[00:53] mn007 | Mmm .
[00:54] me013 | and uh somebody
[00:57] me013 | eh e
"[00:58] me013 | and uh I guess Chuck you weren't there either , so the uh"
[01:01] me018 | I was there .
[01:01] me013 | Oh you were there ?
[01:02] me018 | With Hynek ?
[01:02] me013 | Yeah .
[01:03] me018 | Yeah .
[01:03] me013 | So everybody knows what happened except me .
[01:06] me013 | Maybe somebody should tell me .
[01:12] mn007 | Oh yeah .
[01:13] mn007 | Alright .
[01:15] mn007 | Well . Uh first we discussed about some of the points
[01:19] mn007 | that I was addressing in the mail I sent last week .
[01:23] me013 | Uh - huh .
[01:24] mn007 | So .
[01:26] mn007 | Yeah .
[01:29] mn007 | the downsampling problem .
[01:30] me013 | Yeah .
[01:31] mn007 | Uh and about the f the length of the filters
[01:36] mn007 | Yeah .
[01:38] me013 | What was the w what was the downsampling problem again ? I forget .
[01:40] mn007 | So the fact that there there is no uh low - pass filtering before the downsampling .
[01:45] mn007 | Well .
[01:46] me013 | Uh - huh .
[01:47] mn007 | There is because there is LDA filtering but
[01:50] mn007 | that 's perhaps not
[01:52] mn007 | uh the best w m Well .
[01:54] me013 | Depends what it 's
"[01:56] me013 | frequency characteristic is , yeah ."
[01:56] mn007 | Mm - hmm .
[01:57] me013 | So you could do a you could do a stricter one .
[02:00] me013 | Maybe . Yeah .
[02:01] mn007 | Yeah .
[02:05] me013 | Was there any conclusion about that ?
[02:14] mn007 | Uh .
[02:15] me013 | Yeah . So again this is th this is the downsampling
[02:18] me013 | uh of the uh the feature vector stream
[02:21] me013 | and
[02:22] me013 | um
[02:26] me013 | the uh LDA filters they were doing do have
[02:29] me013 | um
[02:35] me013 | the feature vectors are calculated every ten milliseconds so
[02:38] me013 | uh the question is how far down they are at fifty fifty hertz . Uh .
[02:42] mn007 | Yeah .
[02:43] mn007 | Mm - hmm .
[02:44] me013 | Um .
[02:45] me013 | Sorry at twenty - five hertz since they 're downsampling by two .
[02:48] me013 | So . Does anybody know what the
[02:51] me013 | frequency characteristic is ?
[02:53] mn007 | We don't have yet
[02:54] mn007 | um
[02:54] me013 | Oh OK .
"[02:55] mn007 | So , yeah ."
"[02:56] mn007 | We should have a look first at , perhaps ,"
[02:56] me013 | OK .
[02:58] me013 | Yeah .
[02:59] mn007 | the modulation spectrum .
[03:01] mn007 | Um .
"[03:02] mn007 | So there is this ,"
[03:04] mn007 | there is
[03:04] mn007 | the um length of the filters .
[03:08] mn007 | Um .
[03:10] mn007 | So the i this idea of trying to find filters with shorter delays .
[03:16] mn007 | Um .
[03:17] me013 | Hmm - hmm .
[03:18] mn007 | We started to work with this .
[03:21] mn007 | Mmm .
[03:22] mn007 | And the third point um
"[03:26] mn007 | was the um ,"
"[03:28] mn007 | yeah ,"
"[03:29] mn007 | the on - line normalization where ,"
"[03:32] mn007 | well , the recursion f"
[03:33] mn007 | recursion for the mean estimation
[03:35] mn007 | is a filter with some kind of delay
[03:38] me013 | Yeah .
[03:39] mn007 | and that 's not taken into account right now .
[03:42] mn007 | Um .
[03:44] mn007 | Yeah .
"[03:45] mn007 | And there again , yeah ."
"[03:47] mn007 | For this , the conclusion of Hynek was , well ,"
"[03:50] mn007 | "" we can try it but """
[03:52] me013 | Uh - huh .
[03:53] mn007 | Um .
[03:53] me013 | Try try what ?
[03:55] mn007 | So try
[03:56] mn007 | to um
[03:58] mn007 | um
[03:59] mn007 | take into account the delay of the recursion for the mean estimation .
[04:04] me013 | OK .
[04:06] mn007 | Mmm .
[04:06] mn007 | And this we 've not uh worked on this yet .
"[04:11] mn007 | Um , yeah ."
"[04:14] mn007 | And so while discussing about these these LDA filters ,"
"[04:18] mn007 | some i issues appeared , like"
"[04:21] mn007 | well ,"
[04:21] mn007 | the fact that
[04:23] mn007 | if we look at the frequency response of these filters it 's
"[04:27] mn007 | uh ,"
"[04:27] mn007 | well , we don't know really what 's the important part"
[04:31] mn007 | in the frequency response and there is the fact that
"[04:34] mn007 | in the very low frequency ,"
[04:36] mn007 | these filters don't don't
[04:38] mn007 | really remove a lot .
[04:41] mn007 | to the uh standard RASTA filter .
[04:44] mn007 | Uh and that 's
"[04:45] mn007 | probably a reason why , yeah , on - line normalization helps because"
[04:49] me013 | Right .
[04:53] mn007 | Um .
"[04:56] mn007 | could be in the filter , I mean ,"
[05:03] mn007 | Yeah . So .
[05:10] mn007 | that 's
[05:12] mn007 | all we discussed about . We discussed about
[05:14] mn007 | good things to do also uh
"[05:16] mn007 | well , generally good stuff"
[05:17] me013 | Mm - hmm .
[05:18] mn007 | to do for the research .
[05:20] mn007 | And this was this LDA uh tuning perhaps and
[05:24] mn007 | Hynek proposed again to
"[05:26] mn007 | his uh TRAPS , so ."
[05:30] me013 | OK .
"[05:30] mn007 | Yeah , um ."
[05:33] me013 | is figuring out how to better coordinate between the two sides cuz because um
[05:36] mn007 | Mm - hmm .
[05:39] me013 | uh I was talking with Hynek about it later and the the sort of had
[05:42] me013 | the sense sort of that that neither group of people wanted to to bother the other
[05:47] me013 | group too much .
"[05:49] me013 | And and I don't think anybody is , you know ,"
[05:51] me013 | closed in in their
[05:52] me013 | thinking or are unwilling to talk about things but I think that
[05:56] me013 | you were sort of
[05:56] me013 | waiting for them to
[06:01] me013 | and expected
[06:02] me013 | that they would do certain things and they were sor they didn't wanna bother you and
[06:03] mn007 | Mm - hmm .
[06:10] me013 | they were filling up
[06:12] me013 | all of the
"[06:12] me013 | possible latency themselves , and they just had"
[06:15] me013 | hadn't thought of that . So .
"[06:17] mn007 | Yeah . Well , but . Yeah ."
[06:20] mn007 | Yeah .
[06:21] me013 | I mean it 's true that maybe maybe no one really thought about that that this latency thing would be such a a strict issue
"[06:29] mn007 | Yeah I don't know what happened really , but"
[06:32] me013 | Yeah .
[06:32] mn007 | I guess it 's it 's also so uh
"[06:35] mn007 | the time constraints . Because ,"
"[06:37] mn007 | well , we discussed about that about this problem and"
"[06:40] mn007 | they told us "" well , we will do"
"[06:43] mn007 | all that 's possible to have enough space for a network """
"[06:47] mn007 | but then , yeah ,"
[06:49] me013 | Then they couldn't .
[06:49] mn007 | perhaps they were
[06:50] mn007 | too short with the time and
[06:51] me013 | I see .
[06:53] mn007 | uh yeah .
"[06:55] mn007 | perhaps a problem of communication . So , yeah ."
[06:58] me013 | Just talk more .
"[07:00] mn007 | Yeah , slikes and send mails ."
[07:02] mn007 | u s o o
[07:03] me013 | Yeah .
[07:03] mn007 | Yeah .
[07:04] me013 | Yeah .
[07:05] mn007 | Uh .
[07:06] mn007 | OK .
[07:10] me013 | Alright . Well maybe we should just
[07:12] me013 | uh I mean you 're you 're bus other than that you
[07:14] me013 | folks are busy doing all the all the things that you 're trying that we talked about before right ? And this machines are busy and
[07:21] mn007 | Yeah .
[07:21] me013 | you 're busy and
[07:25] me013 | Yeah .
[07:27] me013 | OK .
[07:27] mn007 | Um .
[07:27] me013 | Oh .
"[07:29] me013 | Let 's let 's , I mean , I think that"
[07:31] me013 | as as we said before that
[07:35] me013 | there will be
[07:36] me013 | uh in the system we end up with there 'll be something to explicitly uh uh
[07:41] me013 | do something about noise
[07:43] me013 | in addition to the
[07:43] mn007 | Mm - hmm .
[07:44] me013 | uh other things that we 're talking about
[07:46] me013 | and that 's probably the best thing to do . And there was that one email that said that
[07:49] me013 | it sounded like uh uh things looked very promising up there
[07:54] me013 | in terms of uh I think they were using Ericsson 's
[07:58] me013 | approach or something and
"[08:01] me013 | They 're doing some noise removal thing , right ?"
"[08:02] mn007 | Yeah , yeah ."
[08:04] mn007 | So yeah we 're will start to do this also .
[08:07] me013 | Yeah .
[08:07] mn007 | Uh so Carmen is just looking at the Ericsson Ericsson code .
[08:08] fn002 | Yeah . We modif
[08:11] me013 | Mm - hmm .
[08:12] mn007 | And
"[08:14] fn002 | I studied Barry 's sim code , more or less ."
[08:16] fn002 | to take @ @ the first step the spectral subtraction .
[08:20] fn002 | and we have some the feature for Italian database
[08:24] fn002 | and we will try with this feature with the filter
[08:26] me013 | Mm - hmm .
[08:28] me013 | Mm - hmm .
[08:29] fn002 | to find the result . But we haven't result until this moment .
"[08:33] me013 | Yeah , sure ."
[08:34] me013 | Yeah .
[08:46] fn002 | No .
"[08:47] fn002 | No , no n we have n we have do the experiment"
[08:52] fn002 | only have the feature the feature but
[08:55] fn002 | the experiment have
[08:57] fn002 | we have not make the experiment and
[08:58] me013 | Oh .
[08:59] me013 | OK .
[09:03] me013 | Yeah .
[09:04] me013 | Yeah .
[09:04] me013 | OK .
[09:12] me013 | what 's what 's
[09:13] me013 | happening in in other areas like
[09:16] me013 | what 's what 's happening with your
[09:19] me013 | investigations
[09:21] me026 | Oh um
[09:21] me013 | about echos and so on .
[09:23] me026 | Well um
"[09:24] me026 | I haven't started writing the test yet , I 'm meeting with Adam today"
[09:27] me013 | Mm - hmm .
[09:27] me026 | um and he 's going t show me the scripts he has for um
[09:31] me026 | running recognition on mee Meeting Recorder digits .
[09:34] me013 | Mm - hmm .
[09:37] me026 | I also um
"[09:38] me026 | haven't got the code yet , I haven't asked Hynek for for the for his code yet ."
[09:42] me026 | Cuz I looked at uh Avendano 's thesis and
[09:48] me026 | it it sounded like um
[09:50] me026 | the channel normalization
[09:52] me026 | part
[09:54] me026 | um
[09:55] me026 | of his thesis um
[09:57] me026 | was done in a a bit of
[09:59] me026 | I don't know what
"[10:00] me026 | the word is , a a bit of a rough way um"
[10:02] me026 | it sounded like he um
[10:05] me026 | he he it it wasn't really fleshed out and maybe he did something that was
[10:10] me026 | interesting for the test situation
[10:12] me026 | but I I 'm not sure if it 's
"[10:13] me026 | what I 'd wanna use so I have to I have to read it more , I don't really understand what he 's doing yet ."
[10:17] me013 | OK .
[10:17] fn002 | It 's my
"[10:18] me013 | Yeah I haven't read it in a while so I 'm not gonna be too much help unless I read it again , so ."
[10:19] fn002 | I know this is mine here .
[10:19] mn007 | Oh yeah ?
[10:22] me013 | OK .
[10:24] me013 | Um .
[10:35] me013 | what we 're calling a cheating experiment
[10:37] me013 | uh of sorts
[10:39] me026 | Uh I
[10:39] me026 | I 'm ho
[10:42] me026 | I 'm hoping Espen will do it .
[10:44] me026 | Um
[10:44] me013 | Ah !
[10:44] me013 | OK .
[10:46] me013 | F um
[10:46] me026 | u
[10:47] me013 | Delegate .
[10:48] me013 | That 's good .
[10:49] me013 | It 's good to delegate .
[10:50] me026 | I I think he 's at least
[10:52] me026 | planning to do it for the
[10:53] me026 | cl close - mike cross - talk and so maybe I can just take whatever setup he has and use it .
[10:57] me013 | Great .
[10:58] me013 | Great .
[10:58] me013 | Yeah actually um
[11:00] me013 | he should uh
[11:02] me013 | I wonder who else is
[11:03] me013 | I think maybe it 's Dan Ellis is going to be doing uh a different cancellation . Um .
[11:09] me013 | One of the things that
[11:10] me013 | people working in the meeting task wanna get at
[11:12] me013 | is they would like to have cleaner
[11:15] me013 | close - miked recordings .
[11:17] me013 | So uh this is especially true for the lapel but even for the close close - miked
[11:21] me013 | uh cases
[11:23] me013 | um we 'd like to be able to have
[11:26] me013 | um
[11:27] me013 | other sounds from
[11:34] me013 | So
[11:34] me013 | what they 're talking about doing is using ec
[11:37] me013 | uh
[11:37] me013 | echo cancellation - like
[11:38] me013 | techniques . It 's not really echo but
[11:40] me013 | uh just um
[11:43] me013 | uh
[11:44] me013 | taking the input from other mikes and using uh
[11:48] me013 | uh
[11:51] me013 | an adaptive filtering approach to remove the effect of that
[11:54] me013 | uh other speech .
[11:56] me013 | So .
[12:01] me013 | some point where
[12:03] me013 | eh uh Eric or somebody was was speaking and he had lots of
[12:07] me013 | silence in his channel and I was saying something to somebody else uh
"[12:14] me013 | it was recognizing my words ,"
[12:16] me013 | which were the background speech
[12:16] me026 | Hmm .
[12:20] me013 | close mike .
[12:21] me013 | Yes .
[12:23] me013 | Oh you it was you I was
"[12:24] me018 | I was wearing the lapel and you were sitting next to me ,"
[12:26] me013 | Yeah .
[12:27] me018 | and I only said one thing but you were talking and it was picking up all your words .
[12:32] me013 | Yeah .
[12:33] me013 | So they would like clean channels .
[12:37] me013 | that purpose uh
[12:38] me013 | they 'd like to pull it out .
[12:41] me013 | I think Dan Ellis or somebody who was working with him was going to uh
[12:45] me013 | work on that .
[12:46] me013 | So .
[12:48] me013 | OK .
[12:51] me013 | Um .
[12:53] me013 | And uh I don't know if we 've talked lately about
[12:56] me013 | the the plans you 're developing that we talked about this morning
[12:59] me013 | uh
"[13:00] me013 | I don't remember if we talked about that last week or not , but"
[13:03] me013 | maybe just a quick reprise of of what we
[13:03] me006 | Yeah .
[13:07] me013 | were saying this morning . Uh .
[13:12] me006 | uh
[13:13] me006 | Larry Saul 's work um just reading reading how how we can take
[13:19] me006 | that as a front - end cuz it it detects these features and they plug it into um back - end so I 've been looking at a lot of
[13:26] me006 | um back - end stuff people have been doing articulatory features
[13:33] me006 | what I can pull off the shelf and plug into um Larry Saul 's work .
[13:38] me018 | What about the stuff that um
[13:40] me018 | Mirjam
[13:41] me018 | has been doing ?
"[13:42] me006 | Oh yeah , sh"
[13:43] me006 | And Shawn ?
"[13:44] me018 | and S Shawn , yeah ."
"[13:45] me006 | Yeah . They 're they 're doing uh neural nets , just just training up a whole bunch of neural nets and"
[13:49] me018 | Oh .
[13:52] me006 | I I think they 're trying to understand um
[13:55] me006 | what 's good
"[13:57] me006 | about neural nets in in terms of , you know , their patterns of errors and"
[14:02] me018 | So they 're training up nets to try to recognize these acoustic features ?
[14:05] me006 | Yeah .
[14:06] me018 | I see .
[14:06] me006 | Yeah .
"[14:11] me013 | uh study and , you know , what are the features that they 're finding ."
"[14:14] me013 | We have this problem with the overloading of the term "" feature "" so"
"[14:17] me013 | uh what are the variables ,"
"[14:19] me013 | what we 're calling this one , what are the variables that they 're found finding useful"
[14:20] mn007 | Hmm .
[14:24] me018 | And their their targets are based on
[14:26] me018 | canonical mappings of phones to
[14:29] me018 | acoustic f
[14:30] me013 | Right . And that 's certainly one thing to do and we 're gonna try and do something more f more fine than that
[14:30] me018 | features .
[14:35] me013 | but uh
[14:36] me013 | um
[14:41] me013 | so
[14:43] me013 | um
"[14:46] me013 | So I guess you know what , I was trying to remember some of the things we were saying ,"
[14:48] me013 | do you ha still have that ?
[14:49] me013 | Yeah .
[14:50] me013 | There 's those
"[14:53] me013 | yeah , some of some of the issues we were talking about was in j"
[14:55] me013 | just
[14:57] me013 | on uh
[15:00] me018 | What does what did um Larry Saul use for it was the sonorant
"[15:05] me018 | uh detector , right ?"
[15:06] me006 | He di he did uh yeah .
[15:08] me018 | H how did he do that ? Wh - what was his detector ?
[15:09] me006 | We - oh .
"[15:10] me006 | Um yeah , it was uh sonorance and he also had a paper on voicing too ."
[15:14] me018 | Mm - hmm .
[15:15] me006 | Um and basically um
[15:18] me006 | in his variables that he used
[15:20] me006 | um or measures of SNR at at sub - bands . Actually critical bands like
[15:24] me018 | Mm - hmm .
[15:26] me006 | um the um measures of correlation and covariance
"[15:26] me018 | Oh , OK ."
[15:30] me006 | um within the sub - bands and um and at the upper level detecting uh sonorance and voicing .
[15:32] me018 | Mm - hmm .
[15:39] me018 | So how did he combine all these features ? What what r mmm
[15:42] me006 | Oh .
[15:42] me018 | classifier did he u
[15:43] me006 | Um he used uh um uh
[15:46] me006 | a a belief - net
[15:48] me006 | where the lower levels of the belief - net are correspond to individual tests of
[15:54] me006 | whether there is sonorance within this critical band
[15:57] me018 | Hmm .
"[16:03] me018 | Oh right . You were talking about that , yeah ."
[16:03] me006 | so if yeah . Yeah .
[16:06] me018 | I see .
[16:08] me013 | And the other thing you were talking about is is is where we get the targets from .
"[16:12] me013 | So I mean , there 's these issues of what are the what are the variables that you use"
[16:15] me013 | and
"[16:16] me013 | do you combine them using the soft "" AND - OR "" or you do something , you know , more complicated"
[16:22] me013 | um
[16:22] me013 | and then the other thing was so where do you get the targets from ?
[16:27] me013 | The initial thing is just the obvious that
[16:29] me013 | we 're discussing is
[16:30] me013 | starting up with phone labels
[16:32] me013 | from somewhere and then
[16:33] me013 | uh doing the transformation .
[16:35] me013 | But then the other thing is to do something better and eh w
[16:38] me013 | why don't you tell us again about this this database ?
[16:41] me006 | Oh OK . Um
"[16:42] me006 | Yeah , so there 's uh a group at um Edinburgh"
[16:47] me006 | is working on um this MOCHA database where
[16:51] me006 | um they have measurements of um articulatory positions . So you you put some some pellets on people 's tongues and lips
[17:00] me018 | Hmm !
[17:01] me006 | and and they can tell
[17:03] me013 | And then tell them to talk naturally ?
[17:07] me006 | Well I guess if you got people who had like um
[17:12] me018 | Pierced tongues and
[17:14] me018 | Yeah .
[17:15] me018 | You could just mount it to that and they wouldn't even notice .
[17:18] me006 | Yeah .
[17:27] me018 | Yeah . I
[17:28] me013 | if you can do the measurements .
[17:29] me018 | That 's right .
[17:30] me018 | You could what you could do is you could sell little rings and stuff with embedded
[17:31] me013 | Yeah .
"[17:34] me018 | you know , transmitters in them and things and"
"[17:36] me013 | Yeah , be cool and help science ."
[17:36] me006 | Yeah .
[17:37] me018 | Yeah .
[17:40] me013 | OK .
"[17:41] me006 | Yeah , so they they they have this they 're working on the database , it 's still it 's still being being uh transcribed and produced ."
[17:49] me006 | Um where either you have um acoustic features at the same or or just uh the acoustic waveform 's being recorded for frame and then
[17:57] me006 | at each frame you have a measurement of of the different positions of um uh articulators .
[18:04] me018 | Hmm !
"[18:05] me018 | There 's a bunch of data that l around ,"
[18:09] me018 | that people have done studies like that w way way back right ? I mean
[18:16] me018 | Yeah .
[18:17] me006 | X - ray database .
[18:19] me006 | Yeah .
[18:19] me006 | It 's
"[18:20] me018 | I remember there was this guy at A T - andT , Randolph ? or r"
[18:23] me018 | What was his name ? Do you remember that guy ?
"[18:26] me018 | Um ,"
"[18:27] me018 | researcher at A T - andT a while back that was studying ,"
[18:30] me018 | trying to do speech recognition from these kinds of features .
[18:33] me006 | Hmm .
[18:33] me018 | I can't remember what his name was .
[18:36] me018 | Dang . Now I 'll think of it .
[18:37] me006 | Hmm .
[18:38] me013 | Do you mean eh but you I mean Mar - you mean
[18:40] me013 | when
[18:43] me018 | Mark Randolph .
[18:43] me013 | Yeah he 's he 's he 's at Motorola now .
[18:45] me018 | Oh is he ? Oh OK .
[18:46] me013 | Yeah .
[18:46] me013 | Yeah .
[18:48] me018 | Yeah .
[18:48] mn007 | Is it the guy that was using the
"[18:52] me018 | I can't remember exactly what he was using , now ."
[18:55] me018 | But I know I just remember it had to do with you know
[18:57] mn007 | Yeah .
[18:57] me018 | uh positional
[18:58] me018 | parameters and trying to m you know
[18:59] mn007 | Mm - hmm .
[19:01] me018 | do speech recognition based on them .
[19:02] me013 | Yeah .
[19:03] me013 | So the only the only
"[19:04] me013 | uh hesitation I had about it since , I mean I haven't see the data is it sounds like"
[19:08] me013 | it 's it 's
[19:10] me013 | continuous variables
[19:11] me013 | and a bunch of them .
[19:13] me018 | Hmm .
[19:13] me013 | And so
"[19:18] me013 | What you really want are these binary labels ,"
[19:21] me013 | and just a few of them .
"[19:28] me013 | I I I worry a little bit that this is a research project in itself ,"
[19:32] me013 | whereas um
[19:34] me013 | if you did something instead that like
[19:36] me013 | um
[19:37] me013 | having some manual annotation
[19:39] me013 | by
"[19:40] me013 | uh you know , linguistics students ,"
[19:45] me013 | there 'd be a limited s
[19:46] me013 | set of things that you could do a as per our discussions with with John before
[19:50] me018 | Mm - hmm .
[19:51] me013 | but
"[19:52] me013 | the things that you could do , like nasality and voicing and a couple other things"
[19:56] me013 | you probably could do reasonably well .
[19:57] me018 | Mm - hmm .
[19:58] me013 | And then there would it would really be uh this uh
[20:02] me013 | uh binary variable .
"[20:03] me013 | Course then , that 's the other question is do you want binary variables . So ."
[20:06] me013 | I mean the other thing you could do is
[20:10] me013 | to uh
[20:11] me013 | get those binary variables
[20:13] me013 | and take the continuous variables from
[20:16] me013 | uh
[20:17] me013 | the uh
"[20:19] me013 | uh the data itself there , but"
[20:24] me018 | just do some kind of clustering ?
"[20:26] me013 | Guess you could , yeah ."
[20:28] me013 | Yeah .
[20:29] me013 | So anyway that 's that 's uh that 's another whole
[20:32] me013 | direction that cou could be looked at .
[20:34] me006 | Mm - hmm .
[20:35] me013 | Um .
[20:36] me013 | Um .
"[20:37] me013 | I mean in general it 's gonna be for new data that you look at , it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to"
[20:46] me006 | Right .
[20:46] me013 | Um .
[20:48] me013 | So .
[20:48] me006 | Right .
[20:50] me018 | So you 're talking about using that data to get
[20:54] me018 | instead of using canonical mappings
[20:56] me006 | Right .
[20:56] me018 | of phones . So you 'd use that data to give you
[21:01] me018 | the true mappings are for each phone ?
[21:03] me006 | Mm - hmm .
[21:03] me018 | I see .
[21:04] me006 | Mm - hmm .
[21:06] me013 | Yeah .
"[21:09] me013 | So wh yeah , where this"
"[21:10] me013 | fits into the rest in in my mind , I guess , is that um"
[21:14] me013 | we 're looking at different
[21:15] me013 | ways that we can combine
[21:20] me013 | of rep
[21:21] me013 | front - end representations
"[21:23] me013 | um in order to get robustness under difficult or even ,"
"[21:26] me013 | you know ,"
[21:27] me013 | typical conditions .
"[21:29] me013 | And part of it , this robustness , seems to come from"
[21:33] me013 | uh
[21:34] me013 | multi - stream or multi - band sorts of things and Saul seems to have
[21:41] me013 | one um articulatory feature .
[21:44] me013 | The question is is can we learn from that
[21:55] me013 | the decision about how
[21:58] me013 | strongly to train the different pieces is based on
[22:02] me013 | uh a a reasonable criterion with hidden variables rather than
[22:06] me013 | um
[22:07] me013 | just assuming
[22:08] me013 | that you should train e e every
[22:11] me013 | detector
[22:12] me013 | uh
[22:13] me013 | with equal strength
[22:15] me013 | towards uh it being this phone or that phone .
[22:19] me018 | Hmm .
[22:19] me013 | Right ?
[22:19] me013 | So it so um
[22:21] me013 | he 's got these
[22:22] me013 | um
[22:24] me013 | uh
[22:25] me013 | uh
"[22:26] me013 | he "" AND 's "" between these different"
[22:29] me013 | features .
"[22:31] me013 | It 's a soft "" AND "" , I guess but in in principle"
[22:34] me013 | you you wanna get a strong concurrence of all the different things that indicate something
"[22:39] me013 | and then he "" OR 's "" across the different soft "" OR 's "" across the different uh"
[22:44] me013 | multi - band channels .
[22:46] me013 | And um
[22:48] me013 | the weight
"[22:51] me013 | yeah , the target"
"[22:52] me013 | for the training of the "" AND "" "" AND ' ed "" things"
[22:55] me013 | is something that 's kept
"[22:57] me013 | uh as a hidden variable ,"
[23:00] me013 | and is learned with EM .
[23:04] me013 | is uh
[23:05] me013 | taking
[23:07] me013 | the phone target and then just back propagating
[23:10] me013 | from that
[23:12] me013 | it 's uh
[23:13] me013 | i It could be for instance
[23:15] me013 | that
[23:16] me013 | for a particular
[23:17] me013 | point in the data
[23:19] me013 | you don't want to um
[23:22] me013 | uh
[23:23] me013 | train a particular band train the
[23:25] me013 | detectors for a particular band . You you wanna ignore
"[23:28] me013 | that band , cuz that 's a Ban - band is a noisy noisy measure ."
[23:32] me013 | We 're we 're still gonna try to train it up .
[23:34] me013 | In our scheme we 're gonna try to train it up
[23:36] me013 | to do as well well as it can at predicting .
[23:39] me013 | Uh . Maybe that 's not the right thing to do .
[23:41] me018 | So he doesn't have to have
[23:43] me018 | truth marks
[23:44] me018 | or Ho -
"[23:45] me006 | F right , and uh he doesn't have to have hard labels ."
[23:46] me013 | Well at the at the
"[23:48] me013 | tail end , yeah , he has to know what 's where it 's sonorant ."
[23:50] me006 | Right . For the full band .
[23:51] me013 | But he 's but what he 's - but what he 's not training up uh what he doesn't
[23:54] me013 | depend on as truth is
[23:56] me013 | um
[23:58] me013 | I guess one way of describing would be
[24:02] me013 | if a sound is sonorant
[24:03] me013 | is it sonorant in this band ? Is it sonorant in that band ? Is it sonorant in that band ?
[24:06] me006 | Right .
[24:07] me013 | i It 's hard to even answer that what you really mean is that the whole sound is sonorant . So
[24:10] me018 | Mm - hmm . OK .
"[24:12] me013 | then it comes down to , you know , to what extent should you make use of information from particular band"
[24:17] me013 | towards making your decision .
[24:19] me018 | I see .
[24:19] me013 | And um
[24:21] me013 | uh
[24:23] me013 | we 're making
[24:23] me013 | in a sense sort of this hard decision that you should you should use everything
[24:29] me013 | with uh equal strength .
"[24:31] me013 | And uh because in the ideal case we would be going for posterior probabilities , if we had"
[24:37] me013 | uh
[24:38] me013 | enough data to really get
[24:39] me013 | posterior probabilities
[24:41] me013 | and if the if we also had enough data so that it was representative of the test data
[24:47] me013 | then we would in fact be doing the right thing to train everything as hard as we can .
[24:52] me013 | But um
[25:01] me018 | So where did he get his uh
[25:02] me018 | his tar his
[25:03] me018 | uh high - level targets about what 's sonorant and what 's not ?
[25:08] me018 | OK .
[25:09] me006 | um at first and then
[25:09] me013 | Yeah .
[25:13] me018 | Uh - huh .
[25:15] me013 | Yeah .
[25:15] me006 | And then uh
[25:16] me006 | he does some fine tuning
[25:18] me006 | um
[25:24] me013 | Yeah .
[25:27] me013 | I mean we ha we have a kind of
[25:30] me013 | iterative training
"[25:31] me013 | because we do this embedded Viterbi ,"
[25:34] me013 | uh so there is some
"[25:36] me013 | something that 's suggested ,"
"[25:40] me013 | I think it s doesn't seem like it 's quite the same ,"
[25:43] me013 | cuz of this cuz then whatever
[25:44] me013 | that
[25:47] me018 | Mm - hmm .
"[25:47] me013 | all bands . Well no , that 's not quite right , we did actually do them separate tried to do them separately"
[25:52] me013 | so that would be a little more like what he did .
[25:55] me013 | Um .
[25:59] me013 | But it 's still
[26:02] me013 | it 's um
[26:03] me013 | setting targets based on where you would say
[26:06] me013 | the sound begins
[26:08] me013 | in a particular band .
[26:11] me013 | Where he 's s this is not a labeling per se .
[26:14] me006 | Mm - hmm .
[26:15] me013 | Might be closer I guess if we did a
[26:17] me013 | soft soft target uh
[26:20] me013 | uh
[26:22] me013 | embedded
[26:23] me013 | neural net training like we 've done a few times uh
[26:29] me013 | do the forward calculations to get the gammas and
[26:32] me013 | train on those .
[26:35] me013 | Mmm .
[26:39] me013 | Uh
[26:40] me013 | what 's next ?
[26:42] me018 | I could say a little bit about w
[26:43] me018 | stuff I 've been
[26:44] me018 | playing with .
[26:45] me013 | Oh .
[26:45] me018 | I um
[26:46] me013 | You 're playing ?
[26:47] me018 | Huh ?
[26:47] me013 | You 're playing ?
"[26:48] me018 | Yes , I 'm playing ."
[26:50] me018 | Um
[26:51] me018 | so I
[26:52] me018 | wanted to do this experiment to see um
[26:56] me018 | uh what happens if we
[26:58] me018 | try to
[26:59] me018 | uh improve the performance of the back - end
[27:02] me018 | recognizer for the Aurora task
[27:04] me018 | and see how that affects things .
[27:10] me018 | this
"[27:10] me018 | plan I had for an experiment , this matrix where"
[27:16] me018 | the original
[27:18] me018 | um
[27:20] me018 | the original system . So there 's the original system trained on
[27:23] me018 | the mel
[27:23] me018 | cepstral features
[27:25] me018 | and then com and then uh
[27:28] me018 | optimize the b
[27:29] me018 | HTK system and run that again .
[27:32] me018 | So look at the difference there
[27:34] me018 | and then
[27:35] me018 | uh
[27:35] me018 | do the same thing for
[27:37] me018 | the ICSI - OGI
[27:39] me018 | front - end .
[27:40] me013 | What which test set was this ?
[27:42] me018 | This is that I looked at ?
[27:44] me013 | Mm - hmm .
[27:44] me018 | Uh I 'm looking at the Italian
[27:45] me013 | Mm - hmm .
[27:46] me018 | right now .
[27:46] me018 | So as far as I 've gotten is I 've
[27:49] me018 | uh
[27:53] me018 | full HTK
[27:54] me018 | system for the Italian
[27:59] me018 | that uh
[28:00] me018 | Stephane had .
[28:01] me018 | So um
[28:05] me018 | I 'm sort of lookin
[28:06] me018 | at the point where I wanna know what should I change
[28:11] me018 | uh
[28:11] me018 | to improve it .
[28:12] me018 | So .
[28:13] me018 | One of the first things I thought of was the fact that they use
[28:16] me018 | the same number of states for all of the
[28:19] me018 | models
[28:20] me013 | Mm - hmm .
[28:20] me018 | and so I went on - line and I
[28:22] me018 | uh found a pronunciation
[28:24] me018 | dictionary for Italian digits
[28:26] me013 | Mm - hmm .
"[28:26] me018 | and just looked at , you know , the number of phones in each"
[28:29] me018 | one of the digits .
[28:31] me018 | Um
"[28:31] me018 | you know , sort of the"
[28:32] me018 | canonical way of
[28:34] me018 | setting up a an HMM system is that you use
[28:37] me018 | um
[28:38] me018 | three states per phone
[28:39] me018 | and um
"[28:41] me018 | so then the the total number of states for a word would just be , you know , the number of phones times three ."
[28:46] me018 | And so when I did that for the
"[28:48] me018 | Italian digits , I got"
"[28:49] me018 | a number of states ,"
[28:50] me018 | ranging on the low end from nine
"[28:52] me018 | to the high end , eighteen ."
[28:54] me018 | Um .
[28:55] me018 | Now you have to really add two to that because in HTK there 's an initial null and a final null
[29:00] me018 | so when they use
[29:01] me018 | uh
"[29:02] me018 | models that have eighteen states , there 're really sixteen"
[29:05] me018 | states . They 've got those initial and final null states .
[29:08] me018 | And so um
[29:10] me018 | their
[29:11] me018 | guess of eighteen states seems to be pretty well matched to
"[29:14] me018 | the two longest words of the Italian digits , the four and five"
[29:19] me013 | Mm - hmm .
"[29:19] me018 | which um , according to my ,"
"[29:21] me018 | you know , sort of off the cuff calculation , should have eighteen states each ."
[29:24] me018 | And so they had sixteen . So that 's pretty close .
[29:26] me018 | Um
[29:29] me018 | most of the words
[29:30] me018 | are sh much shorter .
[29:31] me018 | So the majority of them
[29:33] me018 | wanna have nine states .
[29:34] me018 | And so theirs are s
[29:36] me018 | sort of twice as long .
[29:37] me018 | So
[29:38] me018 | uh
[29:39] me018 | I I printed out a confusion matrix
[29:41] me018 | um
[29:43] me018 | uh for the well - matched
"[29:44] me018 | case ,"
[29:45] me018 | and it turns out that the longest words are actually the ones that do the best .
[29:49] me018 | So my guess about what 's happening is that
[29:53] me018 | the same amount of training data for each of these
[29:55] me018 | digits
[29:56] me018 | and
[29:57] me018 | a fixed length model for all of them
[29:59] me018 | but the actual words for some of them are
[30:03] me018 | half as long
[30:04] me018 | you really
[30:05] me018 | um
"[30:06] me018 | have ,"
"[30:06] me018 | you know ,"
[30:07] me018 | half as much training data for those models .
[30:09] me018 | Because if you have a long word
"[30:11] me018 | and you 're training it to eighteen states ,"
[30:14] me018 | uh
[30:15] me013 | Mm - hmm .
"[30:15] me018 | you know , you 've got the same number of"
"[30:17] me018 | Gaussians , you 've gotta train in each case , but"
"[30:19] me018 | for the shorter words ,"
"[30:21] me018 | you know , the total number of frames is actually half as many ."
[30:24] me013 | Mm - hmm .
[30:24] me018 | So
"[30:25] me018 | it could be that ,"
"[30:28] me018 | because you have so many states , you just don't have enough data to train all those Gaussians ."
[30:32] me018 | So um
[30:34] me018 | I 'm going to try to um create more word - specific
[30:38] me018 | um
[30:40] me018 | uh
[30:40] me018 | prototype H M Ms to start training from .
[30:49] me018 | Mm - hmm .
"[30:50] me013 | for the longer word , but ."
"[30:54] me018 | Yeah so I 'll I 'll ,"
[30:55] me018 | the next experiment I 'm gonna try is to just um you know
[30:59] me018 | create
[31:00] me018 | uh models that seem to be more w matched to
[31:03] me013 | Mm - hmm .
[31:03] me018 | my guess about how long they should be .
[31:06] me018 | And as part of that
[31:07] me018 | um
[31:08] me018 | I wanted to see sort of
[31:13] me018 | how these models were
"[31:14] me018 | coming out , you know , what w"
"[31:16] me018 | when we train up uh th you know , the model for "" one "" , which wants to have"
"[31:19] me018 | nine states , you know ,"
[31:22] me018 | uh what do the transition
"[31:24] me018 | probabilities look like in the self - loops , look like in in those models ?"
[31:28] me018 | And so I talked to Andreas and
[31:29] me018 | he
[31:30] me018 | explained to me how you can
[31:32] me018 | calculate the expected duration
[31:33] me018 | of an HMM just
[31:34] me013 | Mm - hmm .
[31:34] me018 | by looking at the transition
[31:36] me018 | matrix
[31:37] me018 | and so I wrote a little Matlab
[31:38] me018 | script that calculates that and
[31:40] me018 | so I 'm gonna
[31:41] me018 | sort of print those out for each of the words
[31:43] me013 | Mm - hmm .
[31:43] me018 | to see
"[31:44] me018 | what 's happening , you know , how these models are training up , you know , the long ones versus the short ones ."
[31:47] me013 | Mm - hmm .
[31:52] me018 | and um
[31:53] me018 | that 's coming out with about one point two
[31:56] me018 | seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the
[31:59] me013 | Wow .
[32:01] me018 | string of digits .
[32:02] me013 | Lots of silence .
"[32:03] me018 | Yeah , yeah ."
[32:05] me018 | And so the
"[32:06] me018 | S P model , which is what they put in between digits , I I haven't calculated that for that one yet ,"
[32:10] me018 | but um .
[32:13] me018 | their model for a whole digit string is silence
"[32:15] me018 | digit ,"
"[32:16] me018 | SP , digit ,"
[32:17] me018 | SP blah - blah - blah and then silence at the end .
[32:20] me018 | And so .
[32:20] me013 | Are the SP 's optional ? I mean skip them ?
"[32:23] me018 | I have to look at that ,"
[32:25] me018 | but I 'm not sure that they are .
[32:26] me018 | Now the one thing about the S P model is really it only has
[32:29] me018 | a single
[32:31] me018 | s emitting state to it .
[32:33] me013 | Mm - hmm .
"[32:33] me018 | So if it 's not optional ,"
"[32:34] me018 | you know , it 's it 's not gonna hurt a whole lot"
[32:37] me013 | I see .
[32:41] me018 | um
"[32:42] me018 | It doesn't require its own training data , it just shares that state ."
[32:42] me013 | Mm - hmm .
[32:45] me013 | Mm - hmm .
"[32:45] me018 | So it , I mean , it 's pretty good"
"[32:47] me018 | the way that they have it set up ,"
[32:48] me018 | but um
[32:50] me018 | i
[32:50] me018 | So I wanna play with that a little bit more .
"[32:52] me018 | I 'm curious about looking at ,"
[32:53] me018 | you know
[32:54] me018 | how these models have trained and looking at the expected durations
[32:57] me018 | of the models
[32:58] me018 | and I wanna compare that
[33:00] me018 | in the the well - matched case f
"[33:02] me018 | to the unmatched case , and see"
[33:05] me018 | just from looking at the
"[33:06] me018 | durations of these models , you know , what what 's happening ."
"[33:10] me013 | Yeah , I mean , I think that uh , as much as you can , it 's good to"
[33:15] me013 | d
[33:15] me013 | sort of not do anything really tricky .
[33:17] me018 | Mm - hmm .
"[33:18] me013 | Not do anything that 's really finely tuned , but just sort of"
[33:20] me018 | Yeah .
[33:20] me013 | eh you know you t you i z
[33:23] me013 | The premise is kind of you have a a good person look at this for a few weeks and what do you come up with ?
[33:27] me018 | Mm - hmm .
[33:28] me018 | Mm - hmm .
[33:29] me013 | And uh
"[33:30] me018 | And Hynek , when I wa told him"
"[33:31] me018 | about this , he had an interesting point , and that was th um"
[33:35] me018 | the the final models that they end up training up have
[33:38] me018 | I think
[33:38] me018 | probably something on the order of six
[33:40] me018 | Gaussians per state .
"[33:42] me018 | So they 're fairly , you know , hefty models . And Hynek was saying that"
"[33:46] me018 | well , probably in a real application ,"
[33:48] me018 | you wouldn't
[33:49] me018 | have enough compute
[33:50] me018 | to handle models that are very big or complicated .
[33:53] me018 | So in fact what we may want
[33:55] me018 | are simpler models .
[33:57] me013 | Could be .
[33:57] me018 | And compare how they
[33:58] me018 | perform to that . But
"[34:00] me018 | you know , it depends on what"
[34:01] me018 | the actual application is and it 's really hard to know
[34:04] me018 | what your
[34:05] me018 | limits are in terms of how many Gaussians you can have .
"[34:07] me013 | Right . And that , I mean , at the moment that 's not the limitation , so ."
[34:10] me018 | Mm - hmm .
"[34:11] me013 | I mean , I I I what I thought you were gonna say i but which I was thinking was um"
"[34:16] me013 | where did six come from ? Probably came from the same place eighteen came from . You know , so ."
"[34:23] me018 | Yeah , yeah ."
[34:28] me018 | if I start
[34:29] me018 | um
[34:31] me018 | reducing the number of states
[34:32] me018 | for some of these shorter models
[34:34] me018 | that 's gonna reduce the total number of Gaussians . So in a sense it 'll be a simpler
[34:36] me013 | Right .
[34:38] me018 | system .
[34:38] me013 | Yeah .
[34:39] me013 | Yeah .
[34:39] me013 | But I think right now again the idea is doing
[34:43] me013 | just very simple things
[34:44] me018 | Yeah .
[34:45] me013 | how much better can you make it ? And um
[34:46] me018 | Mm - hmm .
[34:48] me013 | since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation um so
[34:52] me018 | Right .
[34:53] me018 | Right .
"[34:54] me013 | if you found that nine was better than six that would be O K , I think , actually ."
[34:57] me018 | Mm - hmm .
[34:58] me018 | Yeah .
[34:58] me013 | Doesn't have to go down .
"[35:00] me018 | I really wasn't even gonna play with that part of the system yet , I was just gonna"
"[35:02] me013 | Mm - hmm , OK ."
"[35:03] me013 | Yeah , just work with the models , yeah ."
[35:04] me018 | the t
"[35:05] me018 | yeah , just look at the length of the models and just see what happens ."
[35:08] me013 | Yeah .
[35:08] me018 | So .
[35:13] me013 | Cool .
[35:15] me013 | OK .
[35:16] me013 | So uh
[35:17] me013 | what 's uh
[35:19] me013 | You you you guys ' plan for the next next week is
[35:23] me013 | just continue on these these same things we 've been talking about
[35:26] me013 | for Aurora and
"[35:27] mn007 | Yeah , I guess we can try to"
[35:30] mn007 | have some kind of new baseline for next week perhaps .
[35:34] mn007 | with all these minor things
[35:38] mn007 | modified .
[35:39] mn007 | And then do
"[35:40] mn007 | other things ,"
"[35:41] mn007 | play with the spectral subtraction ,"
[35:44] mn007 | and
[35:46] mn007 | retry the MSG and things like that .
[35:48] me013 | Yeah .
[35:49] me013 | Yeah .
[35:53] mn007 | Big list ?
[35:58] me013 | So .
[35:59] me013 | Well that 's good . I think
[36:01] me013 | that after all of this uh
[36:03] me013 | um
[36:07] me013 | some point
[36:08] me013 | a little later next year there will be some sort of standard and it 'll get out there and
[36:16] me013 | that has uh
[36:17] me013 | been done by our group of people but
[36:19] me013 | uh
[36:21] me013 | there 's go there 'll be standards after that .
[36:24] me013 | So .
[36:25] me018 | Does anybody know how to um
[36:27] me018 | run Matlab
[36:29] me018 | sort of in batch mode like
[36:31] me018 | you c send it
[36:33] me018 | s a bunch of commands to run and it
[36:34] me018 | gives you the output . Is it possible to do that ?
[36:38] me018 | Yeah ?
[36:42] me018 | Octave .
[36:46] me018 | Ah !
[36:47] me018 | OK .
[36:47] me018 | Great .
[36:48] me018 | Thanks .
[36:48] me006 | Yeah .
[36:49] me018 | I was going crazy trying to do that .
[36:52] me013 | Huh .
[36:54] me006 | Yeah .
[36:54] mn007 | What is Octave so ?
[36:56] me006 | What 's that ?
[36:56] mn007 | It 's
[36:56] mn007 | a free software ?
[36:58] mn007 | Yeah .
[37:02] me006 | r running somewhere .
[37:03] me018 | Great !
[37:04] me006 | Yeah .
[37:04] mn007 | And it does the same syntax and everything eh
[37:17] me006 | uh implement object - oriented type things with Matlab .
"[37:21] me006 | Uh Octave doesn't do that yet , so I think you , Octave is kinda like Matlab"
[37:25] me006 | um four point something or .
[37:27] me018 | If it 'll do like
[37:28] me018 | a lot of the basic
"[37:29] me006 | The basic stuff , right ."
[37:29] me018 | matrix and vector stuff
[37:31] me018 | that 's
[37:32] me018 | perfect .
[37:33] me006 | Yeah .
[37:34] me018 | Great !
"[37:37] me013 | OK , guess we 're done ."
[37:39] me006 | OK .
